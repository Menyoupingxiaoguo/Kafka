<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Confluent.Kafka</name>
    </assembly>
    <members>
        <member name="T:Confluent.Kafka.AdminClient">
            <summary>
                Implements an Apache Kafka admin client.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.DescribeConfigsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.ConfigResource},Confluent.Kafka.Admin.DescribeConfigsOptions)">
            <summary>
                Get the configuration for the specified resources. The returned 
                configuration includes default values and the IsDefault property
                can be used to distinguish them from user supplied values. The 
                value of config entries where IsSensitive is true is always null 
                so that sensitive information is not disclosed. Config entries where
                IsReadOnly is true cannot be updated. This operation is supported 
                by brokers with version 0.11.0.0 or higher.
            </summary>
            <param name="resources">
                The resources (topic and broker resource types are currently 
                supported)
            </param>
            <param name="options">
                The options to use when describing configs.
            </param>
            <returns>
                Configs for the specified resources.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.AlterConfigsAsync(System.Collections.Generic.Dictionary{Confluent.Kafka.Admin.ConfigResource,System.Collections.Generic.List{Confluent.Kafka.Admin.ConfigEntry}},Confluent.Kafka.Admin.AlterConfigsOptions)">
            <summary>
                Update the configuration for the specified resources. Updates are not transactional
                so they may succeed for some resources while fail for others. The configs for a 
                particular resource are updated atomically. This operation is supported by brokers 
                with version 0.11.0.0 or higher. IMPORTANT NOTE: Unspecified configuration properties
                will be reverted to their default values. Furthermore, if you use DescribeConfigsAsync
                to obtain the current set of configuration values, modify them, then use 
                AlterConfigsAsync to set them, you will loose any non-default values that are marked 
                as sensitive because they are not provided by DescribeConfigsAsync.
            </summary>
            <param name="configs">
                The resources with their configs (topic is the only resource type with configs
                that can be updated currently).
            </param>
            <param name="options">
                The options to use when altering configs.
            </param>
            <returns>
                The results of the alter configs requests.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.CreateTopicsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.TopicSpecification},Confluent.Kafka.Admin.CreateTopicsOptions)">
            <summary>
                Create a set of new topics.
            </summary>
            <param name="topics">
                A collection of specifications for the new topics to create.
            </param>
            <param name="options">
                The options to use when creating the topics.
            </param>
            <returns>
                The results of the create topic requests.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.DeleteTopicsAsync(System.Collections.Generic.IEnumerable{System.String},Confluent.Kafka.Admin.DeleteTopicsOptions)">
            <summary>
                Delete a set of topics. This operation is not transactional so it may succeed for some topics while fail
                for others. It may take several seconds after the DeleteTopicsResult returns success for all the brokers to
                become aware that the topics are gone. During this time, topics may continue to be visible via admin 
                operations. If delete.topic.enable is false on the brokers, DeleteTopicsAsync will mark the topics for
                deletion, but not actually delete them. The Task will return successfully in this case.
            </summary>
            <param name="topics">
                The topic names to delete.
            </param>
            <param name="options">
                The options to use when deleting topics.
            </param>
            <returns>
                The results of the delete topic requests.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.CreatePartitionsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.PartitionsSpecification},Confluent.Kafka.Admin.CreatePartitionsOptions)">
            <summary>
                Increase the number of partitions for one or more topics as per
                the supplied PartitionsSpecifications.
            </summary>
            <param name="partitionsSpecifications">
                A collection of PartitionsSpecifications.
            </param>
            <param name="options">
                The options to use when creating the partitions.
            </param>
            <returns>
                The results of the PartitionsSpecification requests.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                Initialize a new AdminClient instance.
            </summary>
            <param name="config">
                A collection of librdkafka configuration parameters 
                (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
                and parameters specific to this client (refer to: 
                <see cref="T:Confluent.Kafka.ConfigPropertyNames" />). Only
                the bootstrap.servers property is required.
            </param>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.#ctor(Confluent.Kafka.Handle)">
            <summary>
                Initialize a new AdminClient instance.
            </summary>
            <param name="handle">
                An underlying librdkafka client handle to use to make broker requests.
                It is valid to provide either a Consumer or Producer handle.
            </param>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.ListGroups(System.TimeSpan)">
             <summary>
                 Get information pertaining to all groups in the Kafka cluster (blocking)
            
                 [API-SUBJECT-TO-CHANGE] - The API associated with this functionality 
                 is subject to change.
             </summary>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.ListGroup(System.String,System.TimeSpan)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocking).
            
                 [API-SUBJECT-TO-CHANGE] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.GetWatermarkOffsets(Confluent.Kafka.TopicPartition)">
            <summary>
                Get the last cached low (oldest available/beginning) and high (newest/end)
                offsets for a topic/partition.
            </summary>
            <remarks>
                This method is only available on instances constructed from a Consumer
                handle. The low offset is updated periodically (if statistics.interval.ms 
                is set) while the high offset is updated on each fetched message set from
                the broker. If there is no cached offset (either low or high, or both) then
                Offset.Invalid will be returned for the respective offset.
            </remarks>
            <param name="topicPartition">
                The topic/partition of interest.
            </param>
            <returns>
                The requested WatermarkOffsets (see that class for additional documentation).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
            <summary>
                Query the Kafka cluster for low (oldest available/beginning) and high (newest/end)
                offsets for the specified topic/partition (blocking).
            </summary>
            <param name="topicPartition">
                The topic/partition of interest.
            </param>
            <param name="timeout">
                The maximum period of time the call may block.
            </param>
            <returns>
                The requested WatermarkOffsets (see that class for additional documentation).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.GetMetadata(System.TimeSpan)">
             <summary>
                 Query the cluster for metadata.
            
                 [API-SUBJECT-TO-CHANGE] - The API associated with this functionality is subject to change.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.GetMetadata(System.String,System.TimeSpan)">
            <summary>
                Query the cluster for metadata for a specific topic.
            
                [API-SUBJECT-TO-CHANGE] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.AdminClient.OnLog">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnLog" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.AdminClient.OnStatistics">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnStatistics" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.AdminClient.OnError">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnError" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.AddBrokers(System.String)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.IClient.AddBrokers(System.String)" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.AdminClient.Name">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.IClient.Name" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.AdminClient.Handle">
            <summary>
                An opaque reference to the underlying librdkafka 
                client instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.Dispose">
            <summary>
                Releases all resources used by this AdminClient. In the current
                implementation, this method may block for up to 100ms. This 
                will be replaced with a non-blocking version in the future.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClient.Dispose(System.Boolean)">
            <summary>
                Releases the unmanaged resources used by the
                <see cref="T:Confluent.Kafka.AdminClient" />
                and optionally disposes the managed resources.
            </summary>
            <param name="disposing">
                true to release both managed and unmanaged resources;
                false to release only unmanaged resources.
            </param>
        </member>
        <member name="T:Confluent.Kafka.Admin.AlterConfigsException">
            <summary>
                Represents an error that occured during an alter configs request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.AlterConfigsException.#ctor(System.Collections.Generic.List{Confluent.Kafka.Admin.AlterConfigsExceptionResult})">
            <summary>
                Initializes a new instance of AlterConfigsException.
            </summary>
            <param name="results">
                The result corresponding to all ConfigResources in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Admin.AlterConfigsException.Results">
            <summary>
                The result corresponding to all ConfigResources in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.AlterConfigsExceptionResult">
            <summary>
                The result of an alter config request for a specific resource.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.AlterConfigsExceptionResult.ConfigResource">
            <summary>
                The resource the result corresponds to.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.AlterConfigsExceptionResult.Error">
            <summary>
                The error (or success) of the alter config request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.AlterConfigsOptions">
            <summary>
                Options for the AlterConfigs method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.AlterConfigsOptions.RequestTimeout">
            <summary>
                The overall request timeout, including broker lookup, request 
                transmission, operation time on broker, and response. If set
                to null, the default request timeout for the AdminClient will
                be used.
            
                Default: null
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.AlterConfigsOptions.ValidateOnly">
            <summary>
                If true, the request should be validated only without altering
                the configs.
            
                Default: false
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.ConfigEntry">
            <summary>
                Encapsulates a config property name / value pair.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntry.Name">
            <summary>
                The config name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntry.Value">
            <summary>
                The config value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.ConfigEntryResult">
            <summary>
                A config property entry, as reported by the Kafka admin api.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.IsDefault">
            <summary>
                Whether or not the config value is the default or was 
                explicitly set.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.IsReadOnly">
            <summary>
                Whether or not the config is read-only (cannot be updated).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.IsSensitive">
            <summary>
                Whether or not the config value is sensitive. The value
                for sensitive configuration values is always returned
                as null.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.Name">
            <summary>
                The config name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.Value">
            <summary>
                The config value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.Source">
            <summary>
                The config source. Refer to 
                <see cref="T:Confluent.Kafka.Admin.ConfigSource" /> for 
                more information.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigEntryResult.Synonyms">
            <summary>
                All config values that may be used as the value of this 
                config along with their source, in the order of precedence.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.ConfigResource">
            <summary>
                A class representing resources that have configs.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigResource.Type">
            <summary>
                The resource type (required)
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigResource.Name">
            <summary>
                The resource name (required)
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.ConfigResource.Equals(System.Object)">
            <summary>
                Tests whether this ConfigResource instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a ConfigResource and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Admin.ConfigResource.GetHashCode">
            <summary>
                Returns a hash code for this ConfigResource.
            </summary>
            <returns>
                An integer that specifies a hash value for this ConfigResource.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Admin.ConfigResource.op_Equality(Confluent.Kafka.Admin.ConfigResource,Confluent.Kafka.Admin.ConfigResource)">
            <summary>
                Tests whether ConfigResource instance a is equal to ConfigResource instance b.
            </summary>
            <param name="a">
                The first ConfigResource instance to compare.
            </param>
            <param name="b">
                The second ConfigResource instance to compare.
            </param>
            <returns>
                true if ConfigResource instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Admin.ConfigResource.op_Inequality(Confluent.Kafka.Admin.ConfigResource,Confluent.Kafka.Admin.ConfigResource)">
            <summary>
                Tests whether ConfigResource instance a is not equal to ConfigResource instance b.
            </summary>
            <param name="a">
                The first ConfigResource instance to compare.
            </param>
            <param name="b">
                The second ConfigResource instance to compare.
            </param>
            <returns>
                true if ConfigResource instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Admin.ConfigResource.ToString">
            <summary>
                Returns a string representation of the ConfigResource object.
            </summary>
            <returns>
                A string representation of the ConfigResource object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Admin.ConfigSource">
            <summary>
                Enumerates the different config sources.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.UnknownConfig">
            <summary>
                Unknown
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.DynamicTopicConfig">
            <summary>
                Dynamic Topic
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.DynamicBrokerConfig">
            <summary>
                Dynamic Broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.DynamicDefaultBrokerConfig">
            <summary>
                Dynamic Default Broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.StaticBrokerConfig">
            <summary>
                Static
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ConfigSource.DefaultConfig">
            <summary>
                Default
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.ConfigSynonym">
            <summary>
                Describes a synonym of a config entry.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigSynonym.Name">
            <summary>
                The config name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigSynonym.Value">
            <summary>
                The config value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.ConfigSynonym.Source">
            <summary>
                The config source. Refer to 
                <see cref="T:Confluent.Kafka.Admin.ConfigSource" /> for 
                more information.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreatePartitionsException">
            <summary>
                Represents an error that occured during a create partitions request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.CreatePartitionsException.#ctor(System.Collections.Generic.List{Confluent.Kafka.Admin.CreatePartitionsExceptionResult})">
            <summary>
                Initialize a new instance of CreatePartitionsException.
            </summary>
            <param name="results">
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsException.Results">
            <summary>
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreatePartitionsExceptionResult">
            <summary>
                The result of a create partitions request for a specific topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsExceptionResult.Topic">
            <summary>
                The topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsExceptionResult.Error">
            <summary>
                The error (or success) of the create partitions request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreatePartitionsOptions">
            <summary>
                Options for the CreatePartitions method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsOptions.ValidateOnly">
            <summary>
                If true, the request should be validated only without creating the partitions.
            
                Default: false
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsOptions.RequestTimeout">
            <summary>
                The overall request timeout, including broker lookup, request 
                transmission, operation time on broker, and response. If set
                to null, the default request timeout for the AdminClient will
                be used.
            
                Default: null
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreatePartitionsOptions.OperationTimeout">
            <summary>
                The broker's operation timeout - the maximum time to wait for
                CreatePartitions before returning a result to the application.
                If set to null, will return immediately upon triggering partition
                creation.
            
                Default: null
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreateTopicExceptionResult">
            <summary>
                The result of a request to create a specific topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicExceptionResult.Topic">
            <summary>
                The topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicExceptionResult.Error">
            <summary>
                The error (or success) of the create topic request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreateTopicsException">
            <summary>
                Represents an error that occured during a create topics request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.CreateTopicsException.#ctor(System.Collections.Generic.List{Confluent.Kafka.Admin.CreateTopicExceptionResult})">
            <summary>
                Initialize a new instance of CreateTopicsException.
            </summary>
            <param name="results">
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicsException.Results">
            <summary>
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.CreateTopicsOptions">
            <summary>
                Options for the CreateTopics method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicsOptions.ValidateOnly">
            <summary>
                If true, the request should be validated on the broker only
                without creating the topic.
            
                Default: false
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicsOptions.RequestTimeout">
            <summary>
                The overall request timeout, including broker lookup, request 
                transmission, operation time on broker, and response. If set
                to null, the default request timeout for the AdminClient will
                be used.
            
                Default: null
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.CreateTopicsOptions.OperationTimeout">
            <summary>
                The broker's operation timeout - the maximum time to wait for
                CreateTopics before returning a result to the application.
                If set to null, will return immediately upon triggering topic
                creation.
            
                Default: null
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DeleteTopicExceptionResult">
            <summary>
                The result of a request to delete a specific topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DeleteTopicExceptionResult.Topic">
            <summary>
                The topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DeleteTopicExceptionResult.Error">
            <summary>
                The error (or success) of the delete topic request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DeleteTopicsException">
            <summary>
                Represents an error that occured during a delete topics request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.DeleteTopicsException.#ctor(System.Collections.Generic.List{Confluent.Kafka.Admin.DeleteTopicExceptionResult})">
            <summary>
                Initializes a new DeleteTopicsException.
            </summary>
            <param name="results">
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Admin.DeleteTopicsException.Results">
            <summary>
                The result corresponding to all topics in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DeleteTopicsOptions">
            <summary>
                Options for the DeleteTopics method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DeleteTopicsOptions.RequestTimeout">
            <summary>
                The overall request timeout, including broker lookup, request 
                transmission, operation time on broker, and response. If set
                to null, the default request timeout for the AdminClient will
                be used.
            
                Default: null
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DeleteTopicsOptions.OperationTimeout">
            <summary>
                The broker's operation timeout - the maximum time to wait for
                DeleteTopics before returning a result to the application.
                If set to null, will return immediately upon triggering topic
                deletion.
            
                Default: null
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DescribeConfigsException">
            <summary>
                Represents an error that occured during a describe configs request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Admin.DescribeConfigsException.#ctor(System.Collections.Generic.List{Confluent.Kafka.Admin.DescribeConfigsExceptionResult})">
            <summary>
                Initializes a new instance of DescribeConfigsException.
            </summary>
            <param name="results">
                The result corresponding to all ConfigResource in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Admin.DescribeConfigsException.Results">
            <summary>
                The result corresponding to all ConfigResources in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DescribeConfigsExceptionResult">
            <summary>
                The result of a request to describe the configs of a specific resource.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.DescribeConfigsExceptionResult.ConfigResource">
            <summary>
                The resource associated with the describe configs request.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DescribeConfigsExceptionResult.Entries">
            <summary>
                Configuration entries for the specified resource.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DescribeConfigsExceptionResult.Error">
            <summary>
                The error (or success) of the describe config request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DescribeConfigsOptions">
            <summary>
                Options for the DescribeConfigs method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DescribeConfigsOptions.RequestTimeout">
            <summary>
                The overall request timeout, including broker lookup, request 
                transmission, operation time on broker, and response. If set
                to null, the default request timeout for the AdminClient will
                be used.
            
                Default: null
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.DescribeConfigsResult">
            <summary>
                The result of a request to describe the configs of a specific resource.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.DescribeConfigsResult.ConfigResource">
            <summary>
                The resource associated with the describe configs request.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.DescribeConfigsResult.Entries">
            <summary>
                Configuration entries for the specified resource.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.PartitionsSpecification">
            <summary>
                Specification for new partitions to be added to a topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.PartitionsSpecification.Topic">
            <summary>
                The topic that the new partitions specification corresponds to.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.PartitionsSpecification.ReplicaAssignments">
            <summary>
                The replica assignments for the new partitions, or null if the assignment
                will be done by the controller. The outer list is indexed by the new 
                partitions relative index, and the inner list contains the broker ids.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.PartitionsSpecification.IncreaseTo">
            <summary>
                The partition count for the specified topic is increased to this value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.ResourceType">
            <summary>
                Enumerates the set of configuration resource types.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ResourceType.Unknown">
            <summary>
                Unknown resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ResourceType.Any">
            <summary>
                Any resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ResourceType.Topic">
            <summary>
                Topic resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ResourceType.Group">
            <summary>
                Group resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Admin.ResourceType.Broker">
            <summary>
                Broker resource
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Admin.TopicSpecification">
            <summary>
                Specification of a new topic to be created via the CreateTopics
                method. This class is used for the same purpose as NewTopic in
                the Java API.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.TopicSpecification.Configs">
            <summary>
                The configuration to use to create the new topic.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.TopicSpecification.Name">
            <summary>
                The name of the topic to be created (required).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.TopicSpecification.NumPartitions">
            <summary>
                The number of partitions for the new topic or -1 (the default) if a 
                replica assignment is specified.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.TopicSpecification.ReplicasAssignments">
            <summary>
                A map from partition id to replica ids (i.e., static broker ids) or null
                if the number of partitions and replication factor are specified
                instead.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Admin.TopicSpecification.ReplicationFactor">
            <summary>
                The replication factor for the new topic or -1 (the default) if a 
                replica assignment is specified instead.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.BrokerMetadata">
            <summary>
                Metadata pertaining to a single Kafka broker.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.BrokerMetadata.#ctor(System.Int32,System.String,System.Int32)">
            <summary>
                Initializes a new BrokerMetadata class instance.
            </summary>
            <param name="brokerId">
                The Kafka broker id.
            </param>
            <param name="host">
                The Kafka broker hostname.
            </param>
            <param name="port">
                The Kafka broker port.
            </param>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.BrokerId">
            <summary>
                Gets the Kafka broker id.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.Host">
            <summary>
                Gets the Kafka broker hostname.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.Port">
            <summary>
                Gets the Kafka broker port.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.BrokerMetadata.ToString">
            <summary>
                Returns a JSON representation of the BrokerMetadata object.
            </summary>
            <returns>
                A JSON representation of the BrokerMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.CommittedOffsets">
            <summary>
                Encapsulates information provided to a Consumer's OnOffsetsCommitted
                event - per-partition offsets and success/error together with overall 
                success/error of the commit operation.
            </summary> 
            <remarks>
                Possible error conditions:
                - Entire request failed: Error is set, but not per-partition errors.
                - All partitions failed: Error is set to the value of the last failed partition, but each partition may have different errors.
                - Some partitions failed: global error is success.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.CommittedOffsets.#ctor(System.Collections.Generic.IList{Confluent.Kafka.TopicPartitionOffsetError},Confluent.Kafka.Error)">
            <summary>
                Initializes a new instance of CommittedOffsets.
            </summary>
            <param name="offsets">
                per-partition offsets and success/error.
            </param>
            <param name="error">
                overall operation success/error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.CommittedOffsets.Error">
            <summary>
                Gets the overall operation success/error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.CommittedOffsets.Offsets">
            <summary>
                Gets the per-partition offsets and success/error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.BrokerAddressFamilyType">
            <summary>
                BrokerAddressFamily enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.BrokerAddressFamilyType.Any">
            <summary>
                Any
            </summary>
        </member>
        <member name="F:Confluent.Kafka.BrokerAddressFamilyType.V4">
            <summary>
                V4
            </summary>
        </member>
        <member name="F:Confluent.Kafka.BrokerAddressFamilyType.V6">
            <summary>
                V6
            </summary>
        </member>
        <member name="T:Confluent.Kafka.SecurityProtocolType">
            <summary>
                SecurityProtocol enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SecurityProtocolType.Plaintext">
            <summary>
                Plaintext
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SecurityProtocolType.Ssl">
            <summary>
                Ssl
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SecurityProtocolType.Sasl_Plaintext">
            <summary>
                Sasl_Plaintext
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SecurityProtocolType.Sasl_Ssl">
            <summary>
                Sasl_Ssl
            </summary>
        </member>
        <member name="T:Confluent.Kafka.PartitionAssignmentStrategyType">
            <summary>
                PartitionAssignmentStrategy enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionAssignmentStrategyType.Range">
            <summary>
                Range
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionAssignmentStrategyType.Roundrobin">
            <summary>
                Roundrobin
            </summary>
        </member>
        <member name="T:Confluent.Kafka.QueuingStrategyType">
            <summary>
                QueuingStrategy enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.QueuingStrategyType.Fifo">
            <summary>
                Fifo
            </summary>
        </member>
        <member name="F:Confluent.Kafka.QueuingStrategyType.Lifo">
            <summary>
                Lifo
            </summary>
        </member>
        <member name="T:Confluent.Kafka.PartitionerType">
            <summary>
                Partitioner enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionerType.Random">
            <summary>
                Random
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionerType.Consistent">
            <summary>
                Consistent
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionerType.Consistent_Random">
            <summary>
                Consistent_Random
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionerType.Murmur2">
            <summary>
                Murmur2
            </summary>
        </member>
        <member name="F:Confluent.Kafka.PartitionerType.Murmur2_Random">
            <summary>
                Murmur2_Random
            </summary>
        </member>
        <member name="T:Confluent.Kafka.AutoOffsetResetType">
            <summary>
                AutoOffsetReset enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.AutoOffsetResetType.Latest">
            <summary>
                Latest
            </summary>
        </member>
        <member name="F:Confluent.Kafka.AutoOffsetResetType.Earliest">
            <summary>
                Earliest
            </summary>
        </member>
        <member name="F:Confluent.Kafka.AutoOffsetResetType.Error">
            <summary>
                Error
            </summary>
        </member>
        <member name="T:Confluent.Kafka.SaslMechanismType">
            <summary>
                SaslMechanism enum values
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SaslMechanismType.Gssapi">
            <summary>
                GSSAPI
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SaslMechanismType.Plain">
            <summary>
                PLAIN
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SaslMechanismType.ScramSha256">
            <summary>
                SCRAM-SHA-256
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SaslMechanismType.ScramSha512">
            <summary>
                SCRAM-SHA-512
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ClientConfig">
            <summary>
                Configuration common to all clients
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.#ctor">
            <summary>
                Initialize a new empty <see cref="T:Confluent.Kafka.ClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.#ctor(Confluent.Kafka.ClientConfig)">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ClientConfig" /> instance based on
                an existing <see cref="T:Confluent.Kafka.ClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ClientConfig" /> instance based on
                an existing key/value pair collection.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.Set(System.String,System.String)">
            <summary>
                Set a configuration property using a string key / value pair.
            </summary>
            <remarks>
                Two scenarios where this is useful: 1. For setting librdkafka
                plugin config properties. 2. You are using a different version of 
                librdkafka to the one provided as a dependency of the Confluent.Kafka
                package and the configuration properties have evolved.
            </remarks>
            <param name="key">
                The configuration property name.
            </param>
            <param name="val">
                The property value.
            </param>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.Get(System.String)">
            <summary>
                Gets a configuration property value given a key. Returns null if 
                the property has not been set.
            </summary>
            <param name="key">
                The configuration property to get.
            </param>
            <returns>
                The configuration property value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.GetInt(System.String)">
            <summary>
                Gets a configuration property int? value given a key.
            </summary>
            <param name="key">
                The configuration property to get.
            </param>
            <returns>
                The configuration property value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.GetBool(System.String)">
            <summary>
                Gets a configuration property bool? value given a key.
            </summary>
            <param name="key">
                The configuration property to get.
            </param>
            <returns>
                The configuration property value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.GetEnum(System.Type,System.String)">
            <summary>
                Gets a configuration property enum value given a key.
            </summary>
            <param name="key">
                The configuration property to get.
            </param>
            <param name="type">
                The enum type of the configuration property.
            </param>
            <returns>
                The configuration property value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.SetObject(System.String,System.Object)">
            <summary>
                Set a configuration property using a key / value pair (null checked).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ClientConfig.properties">
            <summary>
                The configuration properties.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.GetEnumerator">
            <summary>
                	Returns an enumerator that iterates through the property collection.
            </summary>
            <returns>
                    An enumerator that iterates through the property collection.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.ClientConfig.System#Collections#IEnumerable#GetEnumerator">
            <summary>
                	Returns an enumerator that iterates through the property collection.
            </summary>
            <returns>
                    An enumerator that iterates through the property collection.
            </returns>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslMechanism">
            <summary>
                SASL mechanism to use for authentication. Supported: GSSAPI, PLAIN, SCRAM-SHA-256, SCRAM-SHA-512. **NOTE**: Despite the name, you may not configure more than one mechanism.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ClientId">
            <summary>
                Client identifier.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.BootstrapServers">
            <summary>
                Initial list of brokers as a CSV list of broker host or host:port. The application may also use `rd_kafka_brokers_add()` to add brokers during runtime.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.MessageMaxBytes">
            <summary>
                Maximum Kafka protocol request message size.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.MessageCopyMaxBytes">
            <summary>
                Maximum size for message to be copied to buffer. Messages larger than this will be passed by reference (zero-copy) at the expense of larger iovecs.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ReceiveMessageMaxBytes">
            <summary>
                Maximum Kafka protocol response message size. This serves as a safety precaution to avoid memory exhaustion in case of protocol hickups. This value must be at least `fetch.max.bytes`  + 512 to allow for protocol overhead; the value is adjusted automatically unless the configuration property is explicitly set.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.MaxInFlight">
            <summary>
                Maximum number of in-flight requests per broker connection. This is a generic property applied to all broker communication, however it is primarily relevant to produce requests. In particular, note that other mechanisms limit the number of outstanding consumer fetch request per broker to one.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.MetadataRequestTimeoutMs">
            <summary>
                Non-topic request timeout in milliseconds. This is for metadata requests, etc.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.TopicMetadataRefreshIntervalMs">
            <summary>
                Topic metadata refresh interval in milliseconds. The metadata is automatically refreshed on error and connect. Use -1 to disable the intervalled refresh.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.MetadataMaxAgeMs">
            <summary>
                Metadata cache max age. Defaults to topic.metadata.refresh.interval.ms * 3
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.TopicMetadataRefreshFastIntervalMs">
            <summary>
                When a topic loses its leader a new metadata request will be enqueued with this initial interval, exponentially increasing until the topic metadata has been refreshed. This is used to recover quickly from transitioning leader brokers.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.TopicMetadataRefreshSparse">
            <summary>
                Sparse metadata requests (consumes less network bandwidth)
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.TopicBlacklist">
            <summary>
                Topic blacklist, a comma-separated list of regular expressions for matching topic names that should be ignored in broker metadata information as if the topics did not exist.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.Debug">
            <summary>
                A comma-separated list of debug contexts to enable. Detailed Producer debugging: broker,topic,msg. Consumer: consumer,cgrp,topic,fetch
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketTimeoutMs">
            <summary>
                Default timeout for network requests. Producer: ProduceRequests will use the lesser value of `socket.timeout.ms` and remaining `message.timeout.ms` for the first message in the batch. Consumer: FetchRequests will use `fetch.wait.max.ms` + `socket.timeout.ms`. Admin: Admin requests will use `socket.timeout.ms` or explicitly set `rd_kafka_AdminOptions_set_operation_timeout()` value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketBlockingMaxMs">
            <summary>
                **DEPRECATED** No longer used.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketSendBufferBytes">
            <summary>
                Broker socket send buffer size. System default is used if 0.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketReceiveBufferBytes">
            <summary>
                Broker socket receive buffer size. System default is used if 0.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketKeepaliveEnable">
            <summary>
                Enable TCP keep-alives (SO_KEEPALIVE) on broker sockets
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketNagleDisable">
            <summary>
                Disable the Nagle algorithm (TCP_NODELAY) on broker sockets.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SocketMaxFails">
            <summary>
                Disconnect from broker when this number of send failures (e.g., timed out requests) is reached. Disable with 0. WARNING: It is highly recommended to leave this setting at its default value of 1 to avoid the client and broker to become desynchronized in case of request timeouts. NOTE: The connection is automatically re-established.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.BrokerAddressTtl">
            <summary>
                How long to cache the broker address resolving results (milliseconds).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.BrokerAddressFamily">
            <summary>
                Allowed broker IP address families: any, v4, v6
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.EnableSparseConnections">
            <summary>
                When enabled the client will only connect to brokers it needs to communicate with. When disabled the client will maintain connections to all brokers in the cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ReconnectBackoffJitterMs">
            <summary>
                **DEPRECATED** No longer used. See `reconnect.backoff.ms` and `reconnect.backoff.max.ms`.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ReconnectBackoffMs">
            <summary>
                The initial time to wait before reconnecting to a broker after the connection has been closed. The time is increased exponentially until `reconnect.backoff.max.ms` is reached. -25% to +50% jitter is applied to each reconnect backoff. A value of 0 disables the backoff and reconnects immediately.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ReconnectBackoffMaxMs">
            <summary>
                The maximum time to wait before reconnecting to a broker after the connection has been closed.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.StatisticsIntervalMs">
            <summary>
                librdkafka statistics emit interval. The application also needs to register a stats callback using `rd_kafka_conf_set_stats_cb()`. The granularity is 1000ms. A value of 0 disables statistics.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.LogQueue">
            <summary>
                Disable spontaneous log_cb from internal librdkafka threads, instead enqueue log messages on queue set with `rd_kafka_set_log_queue()` and serve log callbacks or events through the standard poll APIs. **NOTE**: Log messages will linger in a temporary queue until the log queue has been set.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.LogThreadName">
            <summary>
                Print internal thread name in log messages (useful for debugging librdkafka internals)
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.LogConnectionClose">
            <summary>
                Log broker disconnects. It might be useful to turn this off when interacting with 0.9 brokers with an aggressive `connection.max.idle.ms` value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.InternalTerminationSignal">
            <summary>
                Signal that librdkafka will use to quickly terminate on rd_kafka_destroy(). If this signal is not set then there will be a delay before rd_kafka_wait_destroyed() returns true as internal threads are timing out their system calls. If this signal is set however the delay will be minimal. The application should mask this signal as an internal signal handler is installed.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ApiVersionRequest">
            <summary>
                Request broker's supported API versions to adjust functionality to available protocol features. If set to false, or the ApiVersionRequest fails, the fallback version `broker.version.fallback` will be used. **NOTE**: Depends on broker version >=0.10.0. If the request is not supported by (an older) broker the `broker.version.fallback` fallback is used.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ApiVersionRequestTimeoutMs">
            <summary>
                Timeout for broker API version requests.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.ApiVersionFallbackMs">
            <summary>
                Dictates how long the `broker.version.fallback` fallback is used in the case the ApiVersionRequest fails. **NOTE**: The ApiVersionRequest is only issued when a new connection to the broker is made (such as after an upgrade).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.BrokerVersionFallback">
            <summary>
                Older broker versions (before 0.10.0) provide no way for a client to query for supported protocol features (ApiVersionRequest, see `api.version.request`) making it impossible for the client to know what features it may use. As a workaround a user may set this property to the expected broker version and the client will automatically adjust its feature set accordingly if the ApiVersionRequest fails (or is disabled). The fallback broker version will be used for `api.version.fallback.ms`. Valid values are: 0.9.0, 0.8.2, 0.8.1, 0.8.0. Any other value, such as 0.10.2.1, enables ApiVersionRequests.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SecurityProtocol">
            <summary>
                Protocol used to communicate with brokers.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslCipherSuites">
            <summary>
                A cipher suite is a named combination of authentication, encryption, MAC and key exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL network protocol. See manual page for `ciphers(1)` and `SSL_CTX_set_cipher_list(3).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslCurvesList">
            <summary>
                The supported-curves extension in the TLS ClientHello message specifies the curves (standard/named, or 'explicit' GF(2^k) or GF(p)) the client is willing to have the server use. See manual page for `SSL_CTX_set1_curves_list(3)`. OpenSSL >= 1.0.2 required.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslSigalgsList">
            <summary>
                The client uses the TLS ClientHello signature_algorithms extension to indicate to the server which signature/hash algorithm pairs may be used in digital signatures. See manual page for `SSL_CTX_set1_sigalgs_list(3)`. OpenSSL >= 1.0.2 required.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslKeyLocation">
            <summary>
                Path to client's private key (PEM) used for authentication.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslKeyPassword">
            <summary>
                Private key passphrase
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslCertificateLocation">
            <summary>
                Path to client's public key (PEM) used for authentication.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslCaLocation">
            <summary>
                File or directory path to CA certificate(s) for verifying the broker's key.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslCrlLocation">
            <summary>
                Path to CRL for verifying broker's certificate validity.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslKeystoreLocation">
            <summary>
                Path to client's keystore (PKCS#12) used for authentication.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SslKeystorePassword">
            <summary>
                Client's keystore (PKCS#12) password.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslKerberosServiceName">
            <summary>
                Kerberos principal name that Kafka runs as, not including /hostname@REALM
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslKerberosPrincipal">
            <summary>
                This client's Kerberos principal name. (Not supported on Windows, will use the logon user's principal).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslKerberosKinitCmd">
            <summary>
                Full kerberos kinit command string, %{config.prop.name} is replaced by corresponding config object value, %{broker.name} returns the broker's hostname.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslKerberosKeytab">
            <summary>
                Path to Kerberos keytab file. Uses system default if not set.**NOTE**: This is not automatically used but must be added to the template in sasl.kerberos.kinit.cmd as ` ... -t %{sasl.kerberos.keytab}`.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslKerberosMinTimeBeforeRelogin">
            <summary>
                Minimum time in milliseconds between key refresh attempts.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslUsername">
            <summary>
                SASL username for use with the PLAIN and SASL-SCRAM-.. mechanisms
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SaslPassword">
            <summary>
                SASL password for use with the PLAIN and SASL-SCRAM-.. mechanism
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.PluginLibraryPaths">
            <summary>
                List of plugin libraries to load (; separated). The library search path is platform dependent (see dlopen(3) for Unix and LoadLibrary() for Windows). If no filename extension is specified the platform-specific extension (such as .dll or .so) will be appended automatically.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.GroupId">
            <summary>
                Client group id string. All clients sharing the same group.id belong to the same group.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.PartitionAssignmentStrategy">
            <summary>
                Name of partition assignment strategy to use when elected group leader assigns partitions to group members.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.SessionTimeoutMs">
            <summary>
                Client group session and failure detection timeout.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.HeartbeatIntervalMs">
            <summary>
                Group session keepalive heartbeat interval.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.GroupProtocolType">
            <summary>
                Group protocol type
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ClientConfig.CoordinatorQueryIntervalMs">
            <summary>
                How often to query for the current client group coordinator. If the currently assigned coordinator is down the configured query interval will be divided by ten to more quickly recover in case of coordinator reassignment.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.AdminClientConfig">
            <summary>
                AdminClient configuration properties
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClientConfig.#ctor">
            <summary>
                Initialize a new empty <see cref="T:Confluent.Kafka.AdminClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClientConfig.#ctor(Confluent.Kafka.ClientConfig)">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.AdminClientConfig" /> instance based on
                an existing <see cref="T:Confluent.Kafka.ClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.AdminClientConfig.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.AdminClientConfig" /> instance based on
                an existing key/value pair collection.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ProducerConfig">
            <summary>
                Producer configuration properties
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ProducerConfig.#ctor">
            <summary>
                Initialize a new empty <see cref="T:Confluent.Kafka.ProducerConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ProducerConfig.#ctor(Confluent.Kafka.ClientConfig)">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ProducerConfig" /> instance based on
                an existing <see cref="T:Confluent.Kafka.ClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ProducerConfig.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ProducerConfig" /> instance based on
                an existing key/value pair collection.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.EnableBackgroundPoll">
            <summary>
                Specifies whether or not the producer should start a background poll 
                thread to receive delivery reports and event notifications. Generally,
                this should be set to true. If set to false, you will need to call 
                the Poll function manually.
            
                default: true
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.EnableDeliveryReports">
            <summary>
                Specifies whether to enable notification of delivery reports. Typically
                you should set this parameter to true. Set it to false for "fire and
                forget" semantics and a small boost in performance.
            
                default: true
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.DeliveryReportFields">
            <summary>
                A comma separated list of fields that may be optionally set in delivery
                reports. Disabling delivery report fields that you do not require will
                improve maximum throughput and reduce memory usage. Allowed values:
                key, value, timestamp, headers, all, none.
            
                default: all
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Confluent.Kafka.ProducerConfig.EnableIdempotence" -->
        <member name="P:Confluent.Kafka.ProducerConfig.EnableGaplessGuarantee">
            <summary>
                When set to `true`, any error that could result in a gap in the produced message series when a batch of messages fails, will raise a fatal error (ERR__GAPLESS_GUARANTEE) and stop the producer. Requires `enable.idempotence=true`.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.QueueBufferingMaxMessages">
            <summary>
                Maximum number of messages allowed on the producer queue.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.QueueBufferingMaxKbytes">
            <summary>
                Maximum total message size sum allowed on the producer queue. This property has higher priority than queue.buffering.max.messages.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.LingerMs">
            <summary>
                Delay in milliseconds to wait for messages in the producer queue to accumulate before constructing message batches (MessageSets) to transmit to brokers. A higher value allows larger and more effective (less overhead, improved compression) batches of messages to accumulate at the expense of increased message delivery latency.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.MessageSendMaxRetries">
            <summary>
                How many times to retry sending a failing MessageSet. **Note:** retrying may cause reordering.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.RetryBackoffMs">
            <summary>
                The backoff time in milliseconds before retrying a protocol request.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.QueueBufferingBackpressureThreshold">
            <summary>
                The threshold of outstanding not yet transmitted broker requests needed to backpressure the producer's message accumulator. If the number of not yet transmitted requests equals or exceeds this number, produce request creation that would have otherwise been triggered (for example, in accordance with linger.ms) will be delayed. A lower number yields larger and more effective batches. A higher value can improve latency when using compression on slow machines.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.BatchNumMessages">
            <summary>
                Maximum number of messages batched in one MessageSet. The total MessageSet size is also limited by message.max.bytes.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.Acks">
            <summary>
                This field indicates how many acknowledgements the leader broker must receive from ISR brokers before responding to the request: *0*=Broker does not send any response/ack to client, *1*=Only the leader broker will need to ack the message, *-1* or *all*=broker will block until message is committed by all in sync replicas (ISRs) or broker's `min.insync.replicas` setting before sending response.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.RequestTimeoutMs">
            <summary>
                The ack timeout of the producer request in milliseconds. This value is only enforced by the broker and relies on `request.required.acks` being != 0.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.MessageTimeoutMs">
            <summary>
                Local message timeout. This value is only enforced locally and limits the time a produced message waits for successful delivery. A time of 0 is infinite. This is the maximum time librdkafka may use to deliver a message (including retries). Delivery error occurs when either the retry count or the message timeout are exceeded.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.QueuingStrategy">
            <summary>
                Producer queuing strategy. FIFO preserves produce ordering, while LIFO prioritizes new messages. WARNING: `lifo` is experimental and subject to change or removal.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.Partitioner">
            <summary>
                Partitioner: `random` - random distribution, `consistent` - CRC32 hash of key (Empty and NULL keys are mapped to single partition), `consistent_random` - CRC32 hash of key (Empty and NULL keys are randomly partitioned), `murmur2` - Java Producer compatible Murmur2 hash of key (NULL keys are mapped to single partition), `murmur2_random` - Java Producer compatible Murmur2 hash of key (NULL keys are randomly partitioned. This is functionally equivalent to the default partitioner in the Java Producer.).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ProducerConfig.CompressionLevel">
            <summary>
                Compression level parameter for algorithm selected by configuration property `compression.codec`. Higher values will result in better compression at the cost of more CPU usage. Usable range is algorithm-dependent: [0-9] for gzip; [0-12] for lz4; only 0 for snappy; -1 = codec-dependent default compression level.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ConsumerConfig">
            <summary>
                Consumer configuration properties
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ConsumerConfig.#ctor">
            <summary>
                Initialize a new empty <see cref="T:Confluent.Kafka.ConsumerConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ConsumerConfig.#ctor(Confluent.Kafka.ClientConfig)">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ConsumerConfig" /> instance based on
                an existing <see cref="T:Confluent.Kafka.ClientConfig" /> instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ConsumerConfig.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                Initialize a new <see cref="T:Confluent.Kafka.ConsumerConfig" /> instance based on
                an existing key/value pair collection.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.ConsumeResultFields">
            <summary>
                A comma separated list of fields that may be optionally set
                in <see cref="T:Confluent.Kafka.ConsumeResult`2" />
                objects returned by the
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.TimeSpan)" />
                method. Disabling fields that you do not require will improve 
                throughput and reduce memory consumption. Allowed values:
                headers, timestamp, topic, all, none
            
                default: all
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.EnableAutoCommit">
            <summary>
                Automatically and periodically commit offsets in the background. Note: setting this to false does not prevent the consumer from fetching previously committed start offsets. To circumvent this behaviour set specific start offsets per partition in the call to assign().
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.AutoCommitIntervalMs">
            <summary>
                The frequency in milliseconds that the consumer offsets are committed (written) to offset storage. (0 = disable). This setting is used by the high-level consumer.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.EnableAutoOffsetStore">
            <summary>
                Automatically store offset of last message provided to application.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.QueuedMinMessages">
            <summary>
                Minimum number of messages per topic+partition librdkafka tries to maintain in the local consumer queue.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.QueuedMaxMessagesKbytes">
            <summary>
                Maximum number of kilobytes per topic+partition in the local consumer queue. This value may be overshot by fetch.message.max.bytes. This property has higher priority than queued.min.messages.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.FetchWaitMaxMs">
            <summary>
                Maximum time the broker may wait to fill the response with fetch.min.bytes.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.MaxPartitionFetchBytes">
            <summary>
                Initial maximum number of bytes per topic+partition to request when fetching messages from the broker. If the client encounters a message larger than this value it will gradually try to increase it until the entire message can be fetched.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.FetchMaxBytes">
            <summary>
                Maximum amount of data the broker shall return for a Fetch request. Messages are fetched in batches by the consumer and if the first message batch in the first non-empty partition of the Fetch request is larger than this value, then the message batch will still be returned to ensure the consumer can make progress. The maximum message batch size accepted by the broker is defined via `message.max.bytes` (broker config) or `max.message.bytes` (broker topic config). `fetch.max.bytes` is automatically adjusted upwards to be at least `message.max.bytes` (consumer config).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.FetchMinBytes">
            <summary>
                Minimum number of bytes the broker responds with. If fetch.wait.max.ms expires the accumulated data will be sent to the client regardless of this setting.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.FetchErrorBackoffMs">
            <summary>
                How long to postpone the next fetch request for a topic+partition in case of a fetch error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.EnablePartitionEof">
            <summary>
                Emit RD_KAFKA_RESP_ERR__PARTITION_EOF event whenever the consumer reaches the end of a partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.CheckCrcs">
            <summary>
                Verify CRC32 of consumed messages, ensuring no on-the-wire or on-disk corruption to the messages occurred. This check comes at slightly increased CPU usage.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumerConfig.AutoOffsetReset">
            <summary>
                Action to take when there is no initial offset in offset store or the desired offset is out of range: 'smallest','earliest' - automatically reset the offset to the smallest offset, 'largest','latest' - automatically reset the offset to the largest offset, 'error' - trigger an error which is retrieved by consuming messages and checking 'message->err'.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ConfigPropertyNames">
            <summary>
                Names of all configuration properties specific to the
                .NET Client.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ConfigPropertyNames.ProducerEnableBackgroundPoll">
            <summary>
                Specifies whether or not the producer should start a background poll 
                thread to receive delivery reports and event notifications. Generally,
                this should be set to true. If set to false, you will need to call 
                the Poll function manually.
            
                default: true
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ConfigPropertyNames.ProducerEnableDeliveryReports">
            <summary>
                Specifies whether to enable notification of delivery reports. Typically
                you should set this parameter to true. Set it to false for "fire and
                forget" semantics and a small boost in performance.
            
                default: true
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ConfigPropertyNames.ProducerDeliveryReportFields">
            <summary>
                A comma separated list of fields that may be optionally set in delivery
                reports. Disabling delivery report fields that you do not require will
                improve maximum throughput and reduce memory usage. Allowed values:
                key, value, timestamp, headers, all, none.
            
                default: all
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ConfigPropertyNames.ConsumerConsumeResultFields">
            <summary>
                A comma separated list of fields that may be optionally set
                in <see cref="T:Confluent.Kafka.ConsumeResult`2" />
                objects returned by the
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.TimeSpan)" />
                method. Disabling fields that you do not require will improve 
                throughput and reduce memory consumption. Allowed values:
                headers, timestamp, topic, all, none
            
                default: all
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ConsumeException">
            <summary>
                Represents an error that occured during message consumption.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ConsumeException.#ctor(Confluent.Kafka.ConsumeResult{System.Byte[],System.Byte[]},Confluent.Kafka.Error)">
            <summary>
                Initialize a new instance of ConsumeException
            </summary>
            <param name="consumerRecord">
                An object that provides information know about the consumer 
                record for which the error occured.
            </param>
            <param name="error">
                The error that occured.
            </param>
        </member>
        <member name="P:Confluent.Kafka.ConsumeException.ConsumerRecord">
            <summary>
                An object that provides information known about the consumer
                record for which the error occured.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Deserializer`1">
            <summary>
                A deserializer for use with <see cref="T:Confluent.Kafka.Consumer`2" />
            </summary>
            <param name="topic">
                The topic the data originated from.
            </param>
            <param name="data">
                The data to deserialize.
            </param>
            <param name="isNull">
                Whether or not the value is null.
            </param>
            <returns>
                The deserialized value.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.DeserializerGenerator`1">
            <summary>
                A generator for <see cref="T:Confluent.Kafka.Deserializer`1" /> instances.
            </summary>
            <param name="forKey">
                Whether or not the deserializer is for use with key data.
            </param>
            <returns>
                The deserializer.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Consumer`2">
            <summary>
                Implements a high-level Apache Kafka consumer.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Consumer`2.assignCallCount">
            <summary>
                keeps track of whether or not assign has been called during
                invocation of a rebalance callback event.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnLog">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnLog" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnError">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnError" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnStatistics">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnStatistics" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Confluent.Kafka.Deserializer{`0},Confluent.Kafka.Deserializer{`1})">
            <summary>
                Creates a new <see cref="T:Confluent.Kafka.Consumer`2" /> instance.
            </summary>
            <param name="config">
                A collection of librdkafka configuration parameters 
                (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
                and parameters specific to this client (refer to: 
                <see cref="T:Confluent.Kafka.ConfigPropertyNames" />).
                At a minimum, 'bootstrap.servers' and 'group.id' must be
                specified.
            </param>
            <param name="keyDeserializer">
                A delegate to use for deserializing keys.
            </param>
            <param name="valueDeserializer">
                A delegate to use for deserializing values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Confluent.Kafka.DeserializerGenerator{`0},Confluent.Kafka.DeserializerGenerator{`1})">
            <summary>
                Creates a new <see cref="T:Confluent.Kafka.Consumer`2" /> instance.
            </summary>
            <param name="config">
                A collection of librdkafka configuration parameters 
                (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
                and parameters specific to this client (refer to: 
                <see cref="T:Confluent.Kafka.ConfigPropertyNames" />).
                At a minimum, 'bootstrap.servers' and 'group.id' must be
                specified.
            </param>
            <param name="keyDeserializerGenerator">
                A delegate to use to create a delegate for deserializing keys.
            </param>
            <param name="valueDeserializerGenerator">
                A delegate to use to create a delegate for deserializing values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Consume(System.TimeSpan)">
            <summary>
                Poll for new messages / events. Blocks until a consume result
                is available or the timeout period has elapsed.
            </summary>
            <param name="timeout">
                The maximum period of time the call may block.
            </param>
            <returns>
                The consume result.
            </returns>
            <remarks>
                OnPartitionsAssigned/Revoked, OnOffsetsCommitted and 
                OnPartitionEOF events may be invoked as a side-effect of 
                calling this method (on the same thread).
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)">
            <summary>
                Poll for new messages / events. Blocks until a consume result
                is available or the operation has been cancelled.
            </summary>
            <param name="cancellationToken">
                A cancellation token that can be used to cancel this operation.
            </param>
            <returns>
                The consume result.
            </returns>
            <remarks>
                OnPartitionsAssigned/Revoked, OnOffsetsCommitted and
                OnPartitionEOF events may be invoked as a side-effect of
                calling this method (on the same thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionsAssigned">
            <summary>
                Raised when a new partition assignment is received.
            
                If you do not call the <see cref="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})" />
                method (or another overload of this method) in a handler added to this event, following execution of your handler(s),
                the consumer will be automatically assigned to the set of partitions as specified in the event data and 
                consumption will resume from the last committed offset for each partition, or if there is no committed offset, in
                accordance with the `auto.offset.reset` configuration property. This default behavior will not occur if you call Assign
                yourself in a handler added to this event. The set of partitions you assign to is not required to match the
                assignment given to you, but typically will.
            </summary>
            <remarks>
                Executes as a side-effect of
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
                (on the same thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionsRevoked">
            <summary>
                Raised when a partition assignment is revoked.
            
                If you do not call the <see cref="M:Confluent.Kafka.Consumer`2.Unassign" /> or 
                <see cref="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})" />
                (or other overload) method in a handler added to this event, all partitions will be 
                automatically unassigned following execution of your handler(s). This default behavior 
                will not occur if you call Unassign (or Assign) yourself in a handler added to this event.
            </summary>
            <remarks>
                Executes as a side-effect of
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
                and <see cref="M:Confluent.Kafka.Consumer`2.Close" />
                (on the same thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnOffsetsCommitted">
            <summary>
                Raised to report the result of (automatic) offset commits.
                Not raised as a result of the use of the Commit method.
            </summary>
            <remarks>
                Executes as a side-effect of
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
                (on the same thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionEOF">
            <summary>
                Raised when the consumer reaches the end of a topic/partition it is reading from.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Assignment">
            <summary>
                Gets the current partition assignment as set by
                <see cref="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartition)" />.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Subscription">
            <summary>
                Gets the current partition subscription as set by
                <see cref="M:Confluent.Kafka.Consumer`2.Subscribe(System.String)" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Subscribe(System.Collections.Generic.IEnumerable{System.String})">
             <summary>
                 Update the subscription set to topics.
            
                 Any previous subscription will be unassigned and unsubscribed first.
            
                 The subscription set denotes the desired topics to consume and this
                 set is provided to the partition assignor (one of the elected group
                 members) for all clients which then uses the configured
                 partition.assignment.strategy to assign the subscription sets's
                 topics's partitions to the consumers, depending on their subscription.
             </summary>
             <param name="topics">
                 The topics to subscribe to. A regex can be specified to subscribe to 
                 the set of all matching topics (which is updated as topics are added
                 / removed). A regex must be front anchored to be recognized as a regex.
                 e.g. ^myregex
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Subscribe(System.String)">
             <summary>
                 Update the subscription set to a single topic.
            
                 Any previous subscription will be unassigned and unsubscribed first.
             </summary>
             <param name="topic">
                 The topic to subscribe to. A regex can be specified to subscribe to 
                 the set of all matching topics (which is updated as topics are added
                 / removed). A regex must be front anchored to be recognized as a regex.
                 e.g. ^myregex
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Unsubscribe">
            <summary>
                Unsubscribe from the current subscription set.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartition)">
             <summary>
                 Update the assignment set to a single <paramref name="partition" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partition">
                 The partition to consume from. Consumption will resume from the last
                 committed offset, or according to the 'auto.offset.reset' configuration
                 parameter if no offsets have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartitionOffset)">
             <summary>
                 Update the assignment set to a single <paramref name="partition" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partition">
                 The partition to consume from. If an offset value of Offset.Invalid
                 (-1001) is specified, consumption will resume from the last committed
                 offset, or according to the 'auto.offset.reset' configuration parameter
                 if no offsets have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. If an offset value of
                 Offset.Invalid (-1001) is specified for a partition, consumption
                 will resume from the last committed offset on that partition, or
                 according to the 'auto.offset.reset' configuration parameter if
                 no offsets have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. Consumption will resume
                 from the last committed offset on each partition, or according
                 to the 'auto.offset.reset' configuration parameter if no offsets
                 have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Unassign">
            <summary>
                Stop consumption and remove the current assignment.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.StoreOffset(Confluent.Kafka.ConsumeResult{`0,`1})">
            <summary>
                Store offsets for a single partition based on the topic/partition/offset
                of a consume result.
            
                The offset will be committed (written) to the offset store according
                to `auto.commit.interval.ms` or manual offset-less commit().
            </summary>
            <remarks>
                `enable.auto.offset.store` must be set to "false" when using this API.
            </remarks>
            <param name="result">
                A consume result used to determine the offset to store and topic/partition.
            </param>
            <returns>
                Current stored offset or a partition specific error.
            </returns>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                Thrown if result is in error.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Store offsets for one or more partitions.
            
                The offset will be committed (written) to the offset store according
                to `auto.commit.interval.ms` or manual offset-less commit().
            </summary>
            <remarks>
                `enable.auto.offset.store` must be set to "false" when using this API.
            </remarks>
            <param name="offsets">
                List of offsets to be commited.
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                Thrown if any of the constituent results is in error. The entire result
                (which may contain constituent results that are not in error) is available
                via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                property of the exception.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Commit(System.Threading.CancellationToken)">
            <summary>
                Commit all offsets for the current assignment.
            </summary>
            <param name="cancellationToken">
                A cancellation token that can be used to cancel this operation
                (currently ignored).
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                Thrown if any of the constituent results is in error. The entire result
                (which may contain constituent results that are not in error) is available
                via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                property of the exception.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Commit(Confluent.Kafka.ConsumeResult{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Commits an offset based on the topic/partition/offset of a ConsumeResult.
                The next message to be read will be that following <paramref name="result" />.
            </summary>
            <param name="result">
                The ConsumeResult instance used to determine the committed offset.
            </param>
            <remarks>
                A consumer which has position N has consumed messages with offsets up to N-1 
                and will next receive the message with offset N. Hence, this method commits an 
                offset of <paramref name="result" />.Offset + 1.
            </remarks>
            <param name="cancellationToken">
                A cancellation token that can be used to cancel this operation
                (currently ignored).
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                Thrown if the result is in error.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Commit(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset},System.Threading.CancellationToken)">
            <summary>
                Commit an explicit list of offsets.
            </summary>
            <remarks>
                Note: A consumer which has position N has consumed messages with offsets up to N-1 
                and will next receive the message with offset N.
            </remarks>
            <param name="offsets">
                The topic/partition offsets to commit.
            </param>
            <param name="cancellationToken">
                A cancellation token that can be used to cancel this operation
                (currently ignored).
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                Thrown if any of the constituent results is in error. The entire result
                (which may contain constituent results that are not in error) is available
                via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                property of the exception.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Seek(Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Seek to <parmref name="offset"/> on the specified topic/partition which is either
                an absolute or logical offset. This must only be done for partitions that are 
                currently being consumed (i.e., have been Assign()ed). To set the start offset for 
                not-yet-consumed partitions you should use the 
                <see cref="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartitionOffset)" /> 
                method (or other overload) instead.
            </summary>
            <param name="tpo">
                The topic/partition to seek on and the offset to seek to.
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Pause(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Pause consumption for the provided list of partitions.
            </summary>
            <param name="partitions">
                The partitions to pause consumption of.
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionException">
                Per partition success or error.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Resume(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Resume consumption for the provided list of partitions.
            </summary>
            <param name="partitions">
                The partitions to resume consumption of.
            </param>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the request failed.
            </exception>
            <exception cref="T:Confluent.Kafka.TopicPartitionException">
                Per partition success or error.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.TimeSpan,System.Threading.CancellationToken)">
             <summary>
                 Retrieve current committed offsets for the specified topic/partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message, or Offset.Invalid in case there was
                 no previous message, or, alternately a partition specific error may also
                 be returned.
             </summary>
             <param name="partitions">
                 the partitions to get the committed offsets for.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <param name="cancellationToken">
                 A cancellation token that can be used to cancel this operation
                 (currently ignored).
             </param>
             <exception cref="T:Confluent.Kafka.KafkaException">
                 Thrown if the request failed.
             </exception>
             <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                 Thrown if any of the constituent results is in error. The entire result
                 (which may contain constituent results that are not in error) is available
                 via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                 property of the exception.
             </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Gets the current positions (offsets) for the specified topics + partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message + 1, or Offset.Invalid in case there was
                 no previous message consumed by this consumer.
             </summary>
             <exception cref="T:Confluent.Kafka.KafkaException">
                 Thrown if the request failed.
             </exception>
             <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                 Thrown if any of the constituent results is in error. The entire result
                 (which may contain constituent results that are not in error) is available
                 via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                 property of the exception.
             </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.OffsetsForTimes(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionTimestamp},System.TimeSpan,System.Threading.CancellationToken)">
             <summary>
                 Look up the offsets for the given partitions by timestamp. The returned
                 offset for each partition is the earliest offset whose timestamp is greater
                 than or equal to the given timestamp in the corresponding partition.
             </summary>
             <remarks>
                 This is a blocking call. It will block for the timeout period if the 
                 partition does not exist. 
            
                 The consumer does not need to be assigned to the requested partitions.
             </remarks>
             <param name="timestampsToSearch">
                 The mapping from partition to the timestamp to look up.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <param name="cancellationToken">
                 A cancellation token that can be used to cancel this operation
                 (currently ignored).
             </param>
             <returns>
                 A mapping from partition to the timestamp and offset of the first message with
                 timestamp greater than or equal to the target timestamp.
             </returns>
             <exception cref="T:Confluent.Kafka.KafkaException">
                 Thrown if the operation fails.
             </exception>
             <exception cref="T:Confluent.Kafka.TopicPartitionOffsetException">
                 Thrown if any of the constituent results is in error. The entire result
                 (which may contain constituent results that are not in error) is available
                 via the <see cref="P:Confluent.Kafka.TopicPartitionOffsetException.Results" />
                 property of the exception.
             </exception>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.MemberId">
            <summary>
                Gets the (dynamic) group member id of this consumer (as 
                set by the broker).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.AddBrokers(System.String)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.IClient.AddBrokers(System.String)" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Name">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.IClient.Name" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Handle">
            <summary>
                An opaque reference to the underlying librdkafka client instance.
                This can be used to construct an AdminClient that utilizes the same
                underlying librdkafka client as this Consumer instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Close">
            <summary>
                Commits offsets, alerts the group coodinator that the consumer is
                exiting the group then releases all resources used by this consumer.
                You should call <see cref="M:Confluent.Kafka.Consumer`2.Close" />
                instead of <see cref="M:Confluent.Kafka.Consumer`2.Dispose" />
                (or just before) to ensure a timely consumer-group rebalance. If you
                do not call <see cref="M:Confluent.Kafka.Consumer`2.Close" />
                or <see cref="M:Confluent.Kafka.Consumer`2.Unsubscribe" />,
                the group will rebalance after a timeout specified by the group's 
                `session.timeout.ms`. Note: the
                <see cref="E:Confluent.Kafka.Consumer`2.OnPartitionsRevoked" />
                and 
                <see cref="E:Confluent.Kafka.Consumer`2.OnOffsetsCommitted" />
                events may be called as a side-effect of calling this method.
            </summary>
            <exception cref="T:Confluent.Kafka.KafkaException">
                Thrown if the operation fails.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Dispose">
            <summary>
                Releases all resources used by this Consumer without
                committing offsets and without alerting the group coordinator
                that the consumer is exiting the group. If you do not call 
                <see cref="M:Confluent.Kafka.Consumer`2.Close" /> or
                <see cref="M:Confluent.Kafka.Consumer`2.Unsubscribe" />
                prior to Dispose, the group will rebalance after a timeout 
                specified by group's `session.timeout.ms`.
                You should commit offsets / unsubscribe from the group before 
                calling this method (typically by calling 
                <see cref="M:Confluent.Kafka.Consumer`2.Close" />).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Dispose(System.Boolean)">
            <summary>
                Releases the unmanaged resources used by the
                <see cref="T:Confluent.Kafka.Consumer`2" />
                and optionally disposes the managed resources.
            </summary>
            <param name="disposing">
                true to release both managed and unmanaged resources;
                false to release only unmanaged resources.
            </param>
        </member>
        <member name="T:Confluent.Kafka.ConsumeResult`2">
            <summary>
                Represents a message consumed from a Kafka cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Topic">
            <summary>
                The topic associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Partition">
            <summary>
                The partition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Offset">
            <summary>
                The partition offset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.TopicPartition">
            <summary>
                The TopicPartition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.TopicPartitionOffset">
            <summary>
                The TopicPartitionOffset assoicated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Message">
            <summary>
                The Kafka message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Key">
            <summary>
                The Kafka message Key.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Value">
            <summary>
                The Kafka message Value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Timestamp">
            <summary>
                The Kafka message timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ConsumeResult`2.Headers">
            <summary>
                The Kafka message headers.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.DeliveryReport`2">
            <summary>
                Encapsulates the result of a successful produce request.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Topic">
            <summary>
                The topic associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Partition">
            <summary>
                The partition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Offset">
            <summary>
                The partition offset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.TopicPartition">
            <summary>
                The TopicPartition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.TopicPartitionOffset">
            <summary>
                The TopicPartitionOffset assoicated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Message">
            <summary>
                The Kafka message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Key">
            <summary>
                The Kafka message Key.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Value">
            <summary>
                The Kafka message Value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Timestamp">
            <summary>
                The Kafka message timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReport`2.Headers">
            <summary>
                The Kafka message headers.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.DeliveryReportResult`2">
            <summary>
                Encapsulates the result of a produce request.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Topic">
            <summary>
                The topic associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Partition">
            <summary>
                The partition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Offset">
            <summary>
                The partition offset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Error">
            <summary>
                An error (or NoError) associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.TopicPartition">
            <summary>
                The TopicPartition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.TopicPartitionOffset">
            <summary>
                The TopicPartitionOffset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.TopicPartitionOffsetError">
            <summary>
                The TopicPartitionOffsetError assoicated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Message">
            <summary>
                The Kafka message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Key">
            <summary>
                The Kafka message Key.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Value">
            <summary>
                The Kafka message Value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Timestamp">
            <summary>
                The Kafka message timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.DeliveryReportResult`2.Headers">
            <summary>
                The Kafka message headers.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Deserializers">
            <summary>
                Deserializers that can be used with <see cref="T:Confluent.Kafka.Consumer`2" />.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.UTF8">
            <summary>
                Deserializes a UTF8 encoded string.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Null">
            <summary>
                Deserializes a null value to a null value.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Ignore">
            <summary>
                'Deserializes' any value to a null value.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Deserializers.Long(System.String,System.ReadOnlySpan{System.Byte},System.Boolean)">
            <summary>
                Deserializes a big endian encoded (network byte ordered) <see cref="T:System.Int64"/> value from a byte array.
            </summary>
            <param name="data">
                A byte array containing the serialized <see cref="T:System.Int64"/> value (big endian encoding)
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="isNull">
                True if the data is null, false otherwise.
            </param>
            <returns>
                The deserialized <see cref="T:System.Int64"/> value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Deserializers.Int32(System.String,System.ReadOnlySpan{System.Byte},System.Boolean)">
            <summary>
                Deserializes a big endian encoded (network byte ordered) <see cref="T:System.Int32"/> value from a byte array.
            </summary>
            <param name="data">
                A byte array containing the serialized <see cref="T:System.Int32"/> value (big endian encoding).
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="isNull">
                True if the data is null, false otherwise.
            </param>
            <returns>
                The deserialized <see cref="T:System.Int32"/> value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Deserializers.Float(System.String,System.ReadOnlySpan{System.Byte},System.Boolean)">
            <summary>
                Deserializes a big endian encoded (network byte ordered) System.Single value from a byte array.
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="data">
                A byte array containing the serialized System.Single value (big endian encoding).
            </param>
            <param name="isNull">
                True if the data is null, false otherwise.
            </param>
            <returns>
                The deserialized System.Single value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Deserializers.Double(System.String,System.ReadOnlySpan{System.Byte},System.Boolean)">
            <summary>
                Deserializes a big endian encoded (network byte ordered) System.Double value from a byte array.
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="data">
                A byte array containing the serialized System.Double value (big endian encoding).
            </param>
            <param name="isNull">
                True if the data is null, false otherwise.
            </param>
            <returns>
                The deserialized System.Double value.
            </returns>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.ByteArray">
            <summary>
                Deserializes a System.Byte[] value (or null).
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Deserializers.Generators">
            <summary>
                Generators for the standard deserializers (simply return the 
                appropriate deserializer regardless of the value of the forKey
                parameter)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.UTF8">
            <summary>
                Generates a UTF8 deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.ByteArray">
            <summary>
                Generates a ByteArray deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Double">
            <summary>
                Generates a Double deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Float">
            <summary>
                Generates a Float deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Int32">
            <summary>
                Generates a Int32 deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Long">
            <summary>
                Generates a Long deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Null">
            <summary>
                Generates a Null deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Deserializers.Generators.Ignore">
            <summary>
                Generates a Ignore deserializer (invariant on the value of forKey)
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Error">
            <summary>
                Represents an error that occured when interacting with a
                Kafka broker or the librdkafka library.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Error.#ctor(Confluent.Kafka.Error)">
            <summary>
                Initialize a new Error instance that is a copy of another.
            </summary>
            <param name="error">
                The error object to initialize from.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.#ctor(Confluent.Kafka.ErrorCode)">
            <summary>
                Initialize a new Error instance from a particular
                <see cref="T:Confluent.Kafka.ErrorCode"/> value.
            </summary>
            <param name="code">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value associated with this Error.
            </param>
            <remarks>
                The reason string associated with this Error will
                be a static value associated with the <see cref="T:Confluent.Kafka.ErrorCode"/>.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Error.#ctor(Confluent.Kafka.ErrorCode,System.String)">
            <summary>
                Initialize a new Error instance from a particular
                <see cref="T:Confluent.Kafka.ErrorCode"/> value and custom <paramref name="reason"/>
                string.
            </summary>
            <param name="code">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value associated with this Error.
            </param>
            <param name="reason">
                A custom reason string associated with the error
                (overriding the static string associated with 
                <paramref name="code"/>).
            </param>
        </member>
        <member name="P:Confluent.Kafka.Error.Code">
            <summary>
                Gets the <see cref="T:Confluent.Kafka.ErrorCode"/> associated with this Error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.Reason">
            <summary>
                Gets a human readable reason string associated with this error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.IsError">
            <summary>
                true if Code != ErrorCode.NoError.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.IsLocalError">
            <summary>
                true if this is error originated locally (within librdkafka), false otherwise.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.IsBrokerError">
            <summary>
                true if this error originated on a broker, false otherwise.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Implicit(Confluent.Kafka.Error)~Confluent.Kafka.ErrorCode">
            <summary>
                Converts the specified Error value to the value of it's Code property.
            </summary>
            <param name="e">
                The Error value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Implicit(Confluent.Kafka.ErrorCode)~Confluent.Kafka.Error">
            <summary>
                Converts the specified <see cref="T:Confluent.Kafka.ErrorCode"/> value to it's corresponding rich Error value.
            </summary>
            <param name="c">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.Equals(System.Object)">
            <summary>
                Tests whether this Error instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is an Error and the Code property values are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.GetHashCode">
            <summary>
                Returns a hash code for this Error value.
            </summary>
            <returns>
                An integer that specifies a hash value for this Error value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Equality(Confluent.Kafka.Error,Confluent.Kafka.Error)">
            <summary>
                Tests whether Error value a is equal to Error value b.
            </summary>
            <param name="a">
                The first Error value to compare.
            </param>
            <param name="b">
                The second Error value to compare.
            </param>
            <returns>
                true if Error values a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Inequality(Confluent.Kafka.Error,Confluent.Kafka.Error)">
            <summary>
                Tests whether Error value a is not equal to Error value b.
            </summary>
            <param name="a">
                The first Error value to compare.
            </param>
            <param name="b">
                The second Error value to compare.
            </param>
            <returns>
                true if Error values a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.ToString">
            <summary>
                Returns the string representation of the error.
                Depending on error source this might be a rich
                contextual error message, or a simple static
                string representation of the error Code.
            </summary>
            <returns>
                A string representation of the Error object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.ErrorCode">
            <summary>
                Enumeration of local and broker generated error codes.
            </summary>
            <remarks>
                Error codes that relate to locally produced errors in 
                librdkafka are prefixed with Local_
            </remarks>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_BadMsg">
            <summary>
                Received message is incorrect
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_BadCompression">
            <summary>
                Bad/unknown compression
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Destroy">
            <summary>
                Broker is going away
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Fail">
            <summary>
                Generic failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Transport">
            <summary>
                Broker transport failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_CritSysResource">
            <summary>
                Critical system resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Resolve">
            <summary>
                Failed to resolve broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_MsgTimedOut">
            <summary>
                Produced message timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_PartitionEOF">
            <summary>
                Reached the end of the topic+partition queue on the broker. Not really an error.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownPartition">
            <summary>
                Permanent: Partition does not exist in cluster.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_FS">
            <summary>
                File or filesystem error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownTopic">
            <summary>
                Permanent: Topic does not exist in cluster.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_AllBrokersDown">
            <summary>
                All broker connections are down.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_InvalidArg">
            <summary>
                Invalid argument, or invalid configuration
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_TimedOut">
            <summary>
                Operation timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_QueueFull">
            <summary>
                Queue is full
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_IsrInsuff">
            <summary>
                ISR count &lt; required.acks
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NodeUpdate">
            <summary>
                Broker node update
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Ssl">
            <summary>
                SSL error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_WaitCoord">
            <summary>
                Waiting for coordinator to become available.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownGroup">
            <summary>
                Unknown client group
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_InProgress">
            <summary>
                Operation in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_PrevInProgress">
            <summary>
                Previous operation in progress, wait for it to finish.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ExistingSubscription">
            <summary>
                This operation would interfere with an existing subscription
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_AssignPartitions">
            <summary>
                Assigned partitions (rebalance_cb)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_RevokePartitions">
            <summary>
                Revoked partitions (rebalance_cb)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Conflict">
            <summary>
                Conflicting use
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_State">
            <summary>
                Wrong state
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownProtocol">
            <summary>
                Unknown protocol
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NotImplemented">
            <summary>
                Not implemented
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Authentication">
            <summary>
                Authentication failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NoOffset">
            <summary>
                No stored offset
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Outdated">
            <summary>
                Outdated
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_TimedOutQueue">
            <summary>
                Timed out in queue
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnsupportedFeature">
            <summary>
                Feature not supported by broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_WaitCache">
            <summary>
                Awaiting cache update
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Intr">
            <summary>
                Operation interrupted
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_KeySerialization">
            <summary>
                Key serialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ValueSerialization">
            <summary>
                Value serialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_KeyDeserialization">
            <summary>
                Key deserialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ValueDeserialization">
            <summary>
                Value deserialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Partial">
            <summary>
                Partial response
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ReadOnly">
            <summary>
                Modification attempted on read-only object
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NoEnt">
            <summary>
                No such entry / item not found
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Underflow">
            <summary>
                Read underflow
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_InvalidType">
            <summary>
                Invalid type
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Unknown">
            <summary>
                Unknown broker error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NoError">
            <summary>
                Success
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OffsetOutOfRange">
            <summary>
                Offset out of range
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidMsg">
            <summary>
                Invalid message
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnknownTopicOrPart">
            <summary>
                Unknown topic or partition
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidMsgSize">
            <summary>
                Invalid message size
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.LeaderNotAvailable">
            <summary>
                Leader not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotLeaderForPartition">
            <summary>
                Not leader for partition
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RequestTimedOut">
            <summary>
                Request timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.BrokerNotAvailable">
            <summary>
                Broker not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.ReplicaNotAvailable">
            <summary>
                Replica not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.MsgSizeTooLarge">
            <summary>
                Message size too large
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.StaleCtrlEpoch">
            <summary>
                StaleControllerEpochCode
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OffsetMetadataTooLarge">
            <summary>
                Offset metadata string too large
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NetworkException">
            <summary>
                Broker disconnected before response received
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupLoadInProress">
            <summary>
                Group coordinator load in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupCoordinatorNotAvailable">
            <summary>
            Group coordinator not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotCoordinatorForGroup">
            <summary>
                Not coordinator for group
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TopicException">
            <summary>
                Invalid topic
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RecordListTooLarge">
            <summary>
                Message batch larger than configured server segment size
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotEnoughReplicas">
            <summary>
                Not enough in-sync replicas
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotEnoughReplicasAfterAppend">
            <summary>
                Message(s) written to insufficient number of in-sync replicas
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidRequiredAcks">
            <summary>
                Invalid required acks value
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.IllegalGeneration">
            <summary>
                Specified group generation id is not valid
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InconsistentGroupProtocol">
            <summary>
                Inconsistent group protocol
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidGroupId">
            <summary>
                Invalid group.id
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnknownMemberId">
            <summary>
                Unknown member
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidSessionTimeout">
            <summary>
                Invalid session timeout
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RebalanceInProgress">
            <summary>
                Group rebalance in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidCommitOffsetSize">
            <summary>
                Commit offset data size is not valid
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TopicAuthorizationFailed">
            <summary>
                Topic authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupAuthorizationFailed">
            <summary>
                Group authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.ClusterAuthorizationFailed">
            <summary>
                Cluster authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidTimestamp">
            <summary>
                Invalid timestamp
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnsupportedSaslMechanism">
            <summary>
                Unsupported SASL mechanism
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.IllegalSaslState">
            <summary>
                Illegal SASL state
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnsupportedVersion">
            <summary>
                Unusupported version
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TopicAlreadyExists">
            <summary>
                Topic already exists
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidPartitions">
            <summary>
                Invalid number of partitions
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidReplicationFactor">
            <summary>
               Invalid replication factor
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidReplicaAssignment">
            <summary>
                Invalid replica assignment
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidConfig">
            <summary>
                Invalid config
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotController">
            <summary>
                Not controller for cluster
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidRequest">
            <summary>
                Invalid request
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnsupportedForMessageFormat">
            <summary>
                Message format on broker does not support request
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.PolicyViolation">
            <summary>
                Isolation policy volation
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OutOfOrderSequenceNumber">
            <summary>
                Broker received an out of order sequence number
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.DuplicateSequenceNumber">
            <summary>
                Broker received a duplicate sequence number
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidProducerEpoch">
            <summary>
                Producer attempted an operation with an old epoch
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidTxnState">
            <summary>
                Producer attempted a transactional operation in an invalid state
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidProducerIdMapping">
            <summary>
                Producer attempted to use a producer id which is not currently assigned to its transactional id
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidTransactionTimeout">
            <summary>
                Transaction timeout is larger than the maximum value allowed by the broker's max.transaction.timeout.ms
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.ConcurrentTransactions">
            <summary>
                Producer attempted to update a transaction while another concurrent operation on the same transaction was ongoing
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TransactionCoordinatorFenced">
            <summary>
                Indicates that the transaction coordinator sending a WriteTxnMarker is no longer the current coordinator for a given producer
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TransactionalIdAuthorizationFailed">
            <summary>
                Transactional Id authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.SecurityDisabled">
            <summary>
                Security features are disabled
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OperationNotAttempted">
            <summary>
                Operation not attempted
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ErrorCodeExtensions">
            <summary>
                Provides extension methods on the ErrorCode enumeration.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ErrorCodeExtensions.GetReason(Confluent.Kafka.ErrorCode)">
            <summary>
                Returns the static error string associated with 
                the particular ErrorCode value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ErrorEvent">
            <summary>
                Encapsulates a librdkafka error and indication of whether or
                not the error should be considered fatal.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ErrorEvent.#ctor(Confluent.Kafka.Error,System.Boolean)">
            <summary>
                Initialize a new ErrorEvent instance 
            </summary>
            <param name="error">
                The error that occured.
            </param>
            <param name="isFatal">
                whether or not the error is fatal.
            </param>
        </member>
        <member name="P:Confluent.Kafka.ErrorEvent.IsFatal">
            <summary>
                Whether or not the event is fatal.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionException">
            <summary>
                Represents an error that occured during a Consumer.Position request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionException.#ctor(System.Collections.Generic.List{Confluent.Kafka.TopicPartitionError})">
            <summary>
                Initializes a new instance of OffsetsRequestExceptoion.
            </summary>
            <param name="results">
                The result corresponding to all topic partitions of the request 
                (whether or not they were in error). At least one of these 
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionException.Results">
            <summary>
                The result corresponding to all ConfigResources in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionOffsetException">
            <summary>
                Represents an error that occured during a Consumer.Position request.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetException.#ctor(System.Collections.Generic.List{Confluent.Kafka.TopicPartitionOffsetError})">
            <summary>
                Initializes a new instance of OffsetsRequestExceptoion.
            </summary>
            <param name="results">
                The result corresponding to all topic partitions of the request 
                (whether or not they were in error). At least one of these 
                results will be in error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetException.Results">
            <summary>
                The result corresponding to all ConfigResources in the request 
                (whether or not they were in error). At least one of these
                results will be in error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.GroupInfo">
            <summary>
                Encapsulates information describing a particular
                Kafka group.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.GroupInfo.#ctor(Confluent.Kafka.BrokerMetadata,System.String,Confluent.Kafka.Error,System.String,System.String,System.String,System.Collections.Generic.List{Confluent.Kafka.GroupMemberInfo})">
            <summary>
                Initializes a new instance of the GroupInfo class.
            </summary>
            <param name="broker">
                Originating broker info.
            </param>
            <param name="group">
                The group name.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.GroupInfo.Error"/> value associated with the information encapsulated by this class.
            </param>
            <param name="state">
                The group state.
            </param>
            <param name="protocolType">
                The group protocol type.
            </param>
            <param name="protocol">
                The group protocol.
            </param>
            <param name="members">
                The group members.
            </param>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Broker">
            <summary>
                Gets the originating-broker info.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Group">
            <summary>
                Gets the group name
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.GroupInfo.Error"/> value associated with the information encapsulated by this class.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.State">
            <summary>
                Gets the group state
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.ProtocolType">
            <summary>
                Gets the group protocol type
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Protocol">
            <summary>
                Gets the group protocol
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Members">
            <summary>
                Gets the group members
            </summary>
        </member>
        <member name="T:Confluent.Kafka.GroupMemberInfo">
            <summary>
                Encapsulates information describing a particular
                member of a Kafka group.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.GroupMemberInfo.#ctor(System.String,System.String,System.String,System.Byte[],System.Byte[])">
            <summary>
                Initializes a new GroupMemberInfo class instance.
            </summary>
            <param name="memberId">
                The member id (generated by the broker).
            </param>
            <param name="clientId">
                The client's client.id.
            </param>
            <param name="clientHost">
                The client's hostname.
            </param>
            <param name="memberMetadata">
                Gets the member metadata (binary). The format of this data depends on the protocol type.
            </param>
            <param name="memberAssignment">
                Gets the member assignment (binary). The format of this data depends on the protocol type.
            </param>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberId">
            <summary>
                Gets the member id (generated by broker).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.ClientId">
            <summary>
                Gets the client's client.id.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.ClientHost">
            <summary>
                Gets the client's hostname.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberMetadata">
            <summary>
                Gets the member metadata (binary). The format of this data depends on the protocol type.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberAssignment">
            <summary>
                Gets the member assignment (binary). The format of this data depends on the protocol type.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Handle">
            <summary>
                A handle for a librdkafka client instance. Also encapsulates 
                a reference to the IClient instance that owns this handle.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Header">
            <summary>
                Represents a kafka message header.
            </summary>
            <remarks>
                Message headers are supported by v0.11 brokers and above.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Header.Key">
            <summary>
                The header key.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Header.Value">
            <summary>
                The header value.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Header.#ctor(System.String,System.Byte[])">
            <summary>
                Create a new Header instance.
            </summary>
            <param name="key">
                The header key.
            </param>
            <param name="value">
                The header value (may be null).
            </param>
        </member>
        <member name="T:Confluent.Kafka.Headers">
            <summary>
                A collection of Kafka message headers.
            </summary>
            <remarks>
                Message headers are supported by v0.11 brokers and above.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Headers.Add(System.String,System.Byte[])">
            <summary>
                Append a new header to the collection.
            </summary>
            <param name="key">
                The header key.
            </param>
            <param name="val">
                The header value (possibly null). Note: A null
                header value is distinct from an empty header
                value (array of length 0).
            </param>
        </member>
        <member name="M:Confluent.Kafka.Headers.Add(Confluent.Kafka.Header)">
            <summary>
                Append a new header to the collection.
            </summary>
            <param name="header">
                The header to add to the collection.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Headers.GetLast(System.String)">
            <summary>
                Get the value of the latest header with the specified key.
            </summary>
            <param name="key">
                The key to get the associated value of.
            </param>
            <returns>
                The value of the latest element in the collection with the specified key.
            </returns>
            <exception cref="T:System.Collections.Generic.KeyNotFoundException">
                The key <paramref name="key" /> was not present in the collection.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Headers.TryGetLast(System.String,System.Byte[]@)">
            <summary>
                Try to get the value of the latest header with the specified key.
            </summary>
            <param name="key">
                The key to get the associated value of.
            </param>
            <param name="lastHeader">
                The value of the latest element in the collection with the 
                specified key, if a header with that key was present in the
                collection.
            </param>
            <returns>
                true if the a value with the specified key was present in 
                the collection, false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Headers.Remove(System.String)">
            <summary>
                Removes all headers for the given key.
            </summary>
            <param name="key">
                The key to remove all headers for
            </param>
        </member>
        <member name="M:Confluent.Kafka.Headers.GetEnumerator">
            <summary>
                Returns an enumerator that iterates through the headers collection.
            </summary>
            <returns>
                An enumerator object that can be used to iterate through the headers collection.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Headers.System#Collections#IEnumerable#GetEnumerator">
            <summary>
                Returns an enumerator that iterates through the headers collection.
            </summary>
            <returns>
                An enumerator object that can be used to iterate through the headers collection.
            </returns>
        </member>
        <member name="P:Confluent.Kafka.Headers.Item(System.Int32)">
            <summary>
                Gets the header at the specified index
            </summary>
            <param key="index">
                The zero-based index of the element to get.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Headers.Count">
            <summary>
                The number of headers in the collection.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.IAdminClient">
            <summary>
                Defines an Apache Kafka admin client.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.ListGroups(System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.ListGroups(System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.ListGroup(System.String,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.ListGroup(System.String,System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.GetWatermarkOffsets(Confluent.Kafka.TopicPartition)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.GetWatermarkOffsets(Confluent.Kafka.TopicPartition)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.GetMetadata(System.String,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.GetMetadata(System.String,System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.GetMetadata(System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.GetMetadata(System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.CreatePartitionsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.PartitionsSpecification},Confluent.Kafka.Admin.CreatePartitionsOptions)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.CreatePartitionsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.PartitionsSpecification},Confluent.Kafka.Admin.CreatePartitionsOptions)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.DeleteTopicsAsync(System.Collections.Generic.IEnumerable{System.String},Confluent.Kafka.Admin.DeleteTopicsOptions)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.DeleteTopicsAsync(System.Collections.Generic.IEnumerable{System.String},Confluent.Kafka.Admin.DeleteTopicsOptions)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.CreateTopicsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.TopicSpecification},Confluent.Kafka.Admin.CreateTopicsOptions)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.CreateTopicsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.TopicSpecification},Confluent.Kafka.Admin.CreateTopicsOptions)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.AlterConfigsAsync(System.Collections.Generic.Dictionary{Confluent.Kafka.Admin.ConfigResource,System.Collections.Generic.List{Confluent.Kafka.Admin.ConfigEntry}},Confluent.Kafka.Admin.AlterConfigsOptions)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.AlterConfigsAsync(System.Collections.Generic.Dictionary{Confluent.Kafka.Admin.ConfigResource,System.Collections.Generic.List{Confluent.Kafka.Admin.ConfigEntry}},Confluent.Kafka.Admin.AlterConfigsOptions)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IAdminClient.DescribeConfigsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.ConfigResource},Confluent.Kafka.Admin.DescribeConfigsOptions)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.AdminClient.DescribeConfigsAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.Admin.ConfigResource},Confluent.Kafka.Admin.DescribeConfigsOptions)" />
            </summary>
        </member>
        <member name="T:Confluent.Kafka.IClient">
            <summary>
                Defines methods common to all client types.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.IClient.Handle">
            <summary>
                An opaque reference to the underlying librdkafka client instance.
                This can be used to construct an AdminClient that utilizes the same
                underlying librdkafka client as this instance.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.IClient.Name">
            <summary>
                Gets the name of this client instance.
                Contains (but is not equal to) the client.id configuration
                parameter.
            </summary>
            <remarks>
                This name will be unique across all client instances
                in a given application which allows log messages to be
                associated with the corresponding instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.IClient.AddBrokers(System.String)">
             <summary>
                 Adds one or more brokers to the Client's list of initial
                 bootstrap brokers. 
            
                 Note: Additional brokers are discovered automatically as
                 soon as the Client connects to any broker by querying the
                 broker metadata. Calling this method is only required in
                 some scenarios where the address of all brokers in the
                 cluster changes.
             </summary>
             <param name="brokers">
                 Comma-separated list of brokers in the same format as 
                 the bootstrap.server configuration parameter.
             </param>
             <remarks>
                 There is currently no API to remove existing configured, 
                 added or learnt brokers.
             </remarks>
             <returns>
                 The number of brokers added. This value includes brokers
                 that may have been specified a second time.
             </returns>
        </member>
        <member name="E:Confluent.Kafka.IClient.OnLog">
             <summary>
                 Raised when there is information that should be logged.
                 If not specified, a default callback that writes to stderr
                 will be used.
             </summary>
             <remarks>
                 By default not many log messages are generated.
            
                 For more verbose logging, specify one or more debug contexts
                 using the 'debug' configuration property. The 'log_level'
                 configuration property is also relevant, however logging is
                 verbose by default given a debug context has been specified,
                 so you typically shouldn't adjust this value.
            
                 Warning: Log handlers are called spontaneously from internal
                 librdkafka threads and the application must not call any
                 Confluent.Kafka APIs from within a log handler or perform any
                 prolonged operations.
             </remarks>
        </member>
        <member name="E:Confluent.Kafka.IClient.OnError">
            <summary>
                Raised on error events e.g. connection failures or all brokers
                down. Note that the client will try to automatically recover from
                errors that are not marked as fatal - these errors should be
                seen as informational rather than catastrophic.
            </summary>
            <remarks>
                On the Consumer, executes as a side-effect of
                <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
                (on the same thread) and on the Producer and AdminClient, on the
                background poll thread.
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.IClient.OnStatistics">
             <summary>
                 Raised on librdkafka statistics events - a JSON
                 formatted string as defined here:
                 https://github.com/edenhill/librdkafka/wiki/Statistics
             </summary>
             <remarks>
                 You can enable statistics and set the statistics interval
                 using the statistics.interval.ms configuration parameter
                 (disabled by default).
            
                 On the Consumer, executes as a side-effect of
                 <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
                 (on the same thread) and on the Producer and AdminClient, on the
                 background poll thread.
             </remarks>
        </member>
        <member name="T:Confluent.Kafka.IConsumer`2">
            <summary>
                Defines a high-level Apache Kafka consumer (with key and 
                value deserialization).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.IConsumer`2.MemberId">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.Consumer`2.MemberId" />
            </summary>
            <value></value>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Consume(System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Consume(System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Consume(System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="E:Confluent.Kafka.IConsumer`2.OnPartitionsAssigned">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.Consumer`2.OnPartitionsAssigned" />
            </summary>
        </member>
        <member name="E:Confluent.Kafka.IConsumer`2.OnPartitionsRevoked">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.Consumer`2.OnPartitionsRevoked" />
            </summary>
        </member>
        <member name="E:Confluent.Kafka.IConsumer`2.OnOffsetsCommitted">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.Consumer`2.OnOffsetsCommitted" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.IConsumer`2.Assignment">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.Consumer`2.Assignment" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.IConsumer`2.Subscription">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.Consumer`2.Subscription" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Subscribe(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Subscribe(System.Collections.Generic.IEnumerable{System.String})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Subscribe(System.String)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Subscribe(System.String)" />
            </summary>
            <param name="topic"></param>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Unsubscribe">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Unsubscribe" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Assign(Confluent.Kafka.TopicPartition)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartition)" />
            </summary>
            <param name="partition"></param>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Assign(Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartitionOffset)" />
            </summary>
            <param name="partition"></param>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Assign(Confluent.Kafka.TopicPartition)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Unassign">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Unassign" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.StoreOffset(Confluent.Kafka.ConsumeResult{`0,`1})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.StoreOffset(Confluent.Kafka.ConsumeResult{`0,`1})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Commit(System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Commit(System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Commit(Confluent.Kafka.ConsumeResult{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Commit(Confluent.Kafka.ConsumeResult{`0,`1},System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Commit(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset},System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Commit(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset},System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Seek(Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Seek(Confluent.Kafka.TopicPartitionOffset)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Pause(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Pause(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Resume(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Resume(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.TimeSpan,System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IConsumer`2.OffsetsForTimes(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionTimestamp},System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.OffsetsForTimes(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionTimestamp},System.TimeSpan,System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="T:Confluent.Kafka.IDeliveryHandler">
            <summary>
                This interface is implemented by types that handle delivery report
                callbacks as a result of calls to Confluent.Kafka.Producer.ProduceAsync().
            </summary>
            <remarks>
                Methods of this interface will be executed on the poll thread and will
                block other operations - consider this when implementing.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.IDeliveryHandler.HandleDeliveryReport(Confluent.Kafka.Producer.UntypedDeliveryReport)">
            <summary>
                This method is called when the delivery report is available
            </summary>
            <param name="deliveryReport">
                The delivery report.
            </param>
        </member>
        <member name="T:Confluent.Kafka.Ignore">
            <summary>
                A type for use in conjunction with IgnoreDeserializer that enables
                message keys or values to be read as null, regardless of their value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Impl.Librdkafka.ProduceVarTag">
            <summary>
                Var-arg tag types, used in producev
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Impl.NativeMethods.NativeMethods">
            <summary>
                This class should be an exact replica of other NativeMethods classes, except
                for the DllName const.
            </summary>
            <remarks>
                This copy/pasting is required because DllName must be const. 
                TODO: generate the NativeMethods classes at runtime (compile C# code) rather
                than copy/paste.
            
                Alternatively, we could have used dlopen to load the native library, but to 
                do that we need to know the absolute path of the native libraries because the
                dlopen call does not know .NET runtime library storage conventions. Unfortunately 
                these are relatively complex, so we prefer to go with the copy/paste solution
                which is relatively simple.
            </remarks>
        </member>
        <member name="T:Confluent.Kafka.Impl.NativeMethods.NativeMethods_Centos7">
            <summary>
                This class should be an exact replica of other NativeMethods classes, except
                for the DllName const.
            </summary>
            <remarks>
                This copy/pasting is required because DllName must be const. 
                TODO: generate the NativeMethods classes at runtime (compile C# code) rather
                than copy/paste.
            
                Alternatively, we could have used dlopen to load the native library, but to 
                do that we need to know the absolute path of the native libraries because the
                dlopen call does not know .NET runtime library storage conventions. Unfortunately 
                these are relatively complex, so we prefer to go with the copy/paste solution
                which is relatively simple.
            </remarks>
        </member>
        <member name="T:Confluent.Kafka.Impl.NativeMethods.NativeMethods_Debian9">
            <summary>
                This class should be an exact replica of other NativeMethods classes, except
                for the DllName const.
            </summary>
            <remarks>
                This copy/pasting is required because DllName must be const. 
                TODO: generate the NativeMethods classes at runtime (compile C# code) rather
                than copy/paste.
            
                Alternatively, we could have used dlopen to load the native library, but to 
                do that we need to know the absolute path of the native libraries because the
                dlopen call does not know .NET runtime library storage conventions. Unfortunately 
                these are relatively complex, so we prefer to go with the copy/paste solution
                which is relatively simple.
            </remarks>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Unknown">
            <summary>
                Unknown configuration name.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Invalid">
            <summary>
                Invalid configuration value.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Ok">
            <summary>
                Configuration okay
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.SetOwner(Confluent.Kafka.IClient)">
            <summary>
                This object is tightly coupled to the referencing Producer /
                Consumer via callback objects passed into the librdkafka
                config. These are not tracked by the CLR, so we need to
                maintain an explicit reference to the containing object here
                so the delegates - which may get called by librdkafka during
                destroy - are guaranteed to exist during finalization.
                Note: objects referenced by this handle (recursively) will 
                not be GC'd at the time of finalization as the freachable
                list is a GC root. Also, the delegates are ok to use since they
                don't have finalizers.
                
                this is a useful reference:
                https://stackoverflow.com/questions/6964270/which-objects-can-i-use-in-a-finalizer-method
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.ThrowIfHandleClosed">
            <summary>
                Prevent AccessViolationException when handle has already been closed.
                Should be called at start of every function using the handle,
                except in ReleaseHandle. 
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.NewTopic(System.String,System.IntPtr)">
            <summary>
                Setting the config parameter to IntPtr.Zero returns the handle of an 
                existing topic, or an invalid handle if a topic with name <paramref name="topic" /> 
                does not exist. Note: Only the first applied configuration for a specific
                topic will be used.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.GetMetadata(System.Boolean,Confluent.Kafka.Impl.SafeTopicHandle,System.Int32)">
            <summary>
                - allTopics=true - request all topics from cluster
                - allTopics=false, topic=null - request only locally known topics (topic_new():ed topics or otherwise locally referenced once, such as consumed topics)
                - allTopics=false, topic=valid - request specific topic
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.DummyOffsetCommitCb(System.IntPtr,Confluent.Kafka.ErrorCode,System.IntPtr,System.IntPtr)">
            <summary>
                Dummy commit callback that does nothing but prohibits
                triggering the global offset_commit_cb.
                Used by manual commits.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.GetCTopicPartitionList(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Creates and returns a C rd_kafka_topic_partition_list_t * populated by offsets.
            </summary>
            <returns>
                If offsets is null a null IntPtr will be returned, else a IntPtr
                which must destroyed with LibRdKafka.topic_partition_list_destroy()
            </returns>
        </member>
        <member name="T:Confluent.Kafka.StringExtensions">
            <summary>
                Extension methods for the <see cref="T:System.String"/> class.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TimeSpanExtensions">
            <summary>
                Extension methods for the <see cref="T:System.TimeSpan"/> class.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TimeSpanExtensions.TotalMillisecondsAsInt(System.TimeSpan)">
            <summary>
                Converts the TimeSpan value <paramref name="timespan" /> to an integer number of milliseconds.
                An <see cref="T:System.OverflowException"/> is thrown if the number of milliseconds is greater than Int32.MaxValue.
            </summary>
            <param name="timespan">
                The TimeSpan value to convert to milliseconds.
            </param>
            <returns>
                The TimeSpan value <paramref name="timespan" /> in milliseconds.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Internal.Util.Marshal.PtrToStringUTF8(System.IntPtr)">
            <summary>
                Interpret a zero terminated c string as UTF-8.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Internal.Util.Marshal.PtrToStructureUnsafe``1(System.IntPtr)">
            <summary>
                Reinterpret_cast without strings marshaling
            </summary>
            <typeparam name="T">
                Type of struct to cast
            </typeparam>
            <param name="ptr">
                Raw pointer to use
            </param>
            <returns>
                A value of type <typeparamref name="T"/>
            </returns>
        </member>
        <member name="T:Confluent.Kafka.IProducer`2">
            <summary>
                Defines a high-level Apache Kafka producer client that provides key
                and value serialization.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.ProduceAsync(System.String,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.ProduceAsync(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.BeginProduce(System.String,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.BeginProduce(System.String,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.BeginProduce(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.BeginProduce(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.Poll(System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.Poll(System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.Flush(System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.Flush(System.TimeSpan)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IProducer`2.Flush(System.Threading.CancellationToken)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.Flush(System.Threading.CancellationToken)" />
            </summary>
        </member>
        <member name="T:Confluent.Kafka.KafkaException">
            <summary>
                Represents an error that occured during an interaction with Kafka.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.Error)">
            <summary>
                Initialize a new instance of KafkaException based on 
                an existing Error instance.
            </summary>
            <param name="error"> 
                The Kafka Error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.Error,System.Exception)">
            <summary>
                Initialize a new instance of KafkaException based on
                an existing Error instance and inner exception.
            </summary>
            <param name="error">
                The Kafka Error.
            </param>
            <param name="innerException">
                The exception instance that caused this exception.
            </param>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.ErrorCode)">
            <summary>
                Initialize a new instance of KafkaException based on 
                an existing ErrorCode value.
            </summary>
            <param name="code"> 
                The Kafka ErrorCode.
            </param>
        </member>
        <member name="P:Confluent.Kafka.KafkaException.Error">
            <summary>
                Gets the Error associated with this KafkaException.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Library">
            <summary>
                Methods that relate to the native librdkafka library itself
                (do not require a Producer or Consumer broker connection).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.Version">
             <summary>
                 Gets the librdkafka version as an integer.
            
                 Interpreted as hex MM.mm.rr.xx:
                     - MM = Major
                     - mm = minor
                     - rr = revision
                     - xx = pre-release id (0xff is the final release)
            
                 E.g.: 0x000901ff = 0.9.1
             </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.VersionString">
            <summary>
                Gets the librdkafka version as string.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.DebugContexts">
            <summary>
                Gets a list of the supported debug contexts.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.IsLoaded">
            <summary>
                true if librdkafka has been successfully loaded, false if not.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Library.Load">
            <summary>
                Loads the native librdkafka library. Does nothing if the library is
                already loaded.
            </summary>
            <returns>
                true if librdkafka was loaded as a result of this call, false if the
                library has already been loaded.
            </returns>
            <remarks>
                You will not typically need to call this method - librdkafka is loaded
                automatically on first use of a Producer or Consumer instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Library.Load(System.String)">
            <summary>
                Loads the native librdkafka library from the specified path (note: the 
                specified path needs to include the filename). Does nothing if the 
                library is already loaded.
            </summary>
            <returns>
                true if librdkafka was loaded as a result of this call, false if the
                library has already been loaded.
            </returns>
            <remarks>
                You will not typically need to call this method - librdkafka is loaded
                automatically on first use of a Producer or Consumer instance.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Library.HandleCount">
            <summary>
                The total number librdkafka client instances that have been
                created and not yet disposed.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Loggers">
            <summary>
                OnLog callback event handler implementations.
            </summary>
            <remarks>
                Warning: Log handlers are called spontaneously from internal librdkafka 
                threads and the application must not call any Confluent.Kafka APIs from 
                within a log handler or perform any prolonged operations.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Loggers.ConsoleLogger(Confluent.Kafka.LogMessage)">
            <summary>
                The method used to log messages by default.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.LogMessage">
            <summary>
                Encapsulates information provided to the 
                Producer/Consumer OnLog event.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.LogMessage.#ctor(System.String,Confluent.Kafka.SyslogLevel,System.String,System.String)">
            <summary>
                Instantiates a new LogMessage class instance.
            </summary> 
            <param name="name">
                The librdkafka client instance name.
            </param>
            <param name="level">
                The log level (levels correspond to syslog(3)), lower is worse.
            </param>
            <param name="facility">
                The facility (section of librdkafka code) that produced the message.
            </param>
            <param name="message">
                The log message.
            </param>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Name">
            <summary>
                Gets the librdkafka client instance name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Level">
            <summary>
                Gets the log level (levels correspond to syslog(3)), lower is worse.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Facility">
            <summary>
                Gets the facility (section of librdkafka code) that produced the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Message">
            <summary>
                Gets the log message.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Message">
            <summary>
                Represents a message stored in Kafka.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Value">
            <summary>
                Gets the message value (possibly null).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Key">
            <summary>
                Gets the message key value (possibly null).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Timestamp">
            <summary>
                The message timestamp. The timestamp type must be set to CreateTime. 
                Specify Timestamp.Default to set the message timestamp to the time
                of this function call.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Headers">
            <summary>
                The collection of message headers (or null). Specifying null or an 
                 empty list are equivalent. The order of headers is maintained, and
                duplicate header keys are allowed.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Message`2">
            <summary>
                Represents a (deserialized) message stored in Kafka.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Key">
            <summary>
                Gets the message key value (possibly null).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Value">
            <summary>
                Gets the message value (possibly null).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Timestamp">
            <summary>
                The message timestamp. The timestamp type must be set to CreateTime. 
                Specify Timestamp.Default to set the message timestamp to the time
                of this function call.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Headers">
            <summary>
                The collection of message headers (or null). Specifying null or an 
                 empty list are equivalent. The order of headers is maintained, and
                duplicate header keys are allowed.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Metadata">
            <summary>
                Kafka cluster metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Metadata.#ctor(System.Collections.Generic.List{Confluent.Kafka.BrokerMetadata},System.Collections.Generic.List{Confluent.Kafka.TopicMetadata},System.Int32,System.String)">
            <summary>
                Instantiates a new Metadata class instance.
            </summary>
            <param name="brokers">
                Information about each constituent broker of the cluster.
            </param>
            <param name="topics">
                Information about requested topics in the cluster.
            </param>
            <param name="originatingBrokerId">
                The id of the broker that provided this metadata.
            </param>
            <param name="originatingBrokerName">
                The name of the broker that provided this metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Metadata.Brokers">
            <summary>
                Gets information about each constituent broker of the cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.Topics">
            <summary>
                Gets information about requested topics in the cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.OriginatingBrokerId">
            <summary>
                Gets the id of the broker that provided this metadata.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.OriginatingBrokerName">
            <summary>
                Gets the name of the broker that provided this metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Metadata.ToString">
            <summary>
                Returns a JSON representation of the Metadata object.
            </summary>
            <returns>
                A JSON representation of the Metadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Null">
            <summary>
                A type for use in conjunction with NullSerializer and NullDeserializer
                that enables null key or values to be enforced when producing or 
                consuming messages.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Offset">
            <summary>
                Represents a Kafka partition offset value.
            </summary>  
            <remarks>
                This structure is the same size as a long - 
                its purpose is to add some syntactical sugar 
                related to special values.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Offset.Beginning">
            <summary>
                A special value that refers to the beginning of a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.End">
            <summary>
                A special value that refers to the end of a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.Stored">
            <summary>
                A special value thet refers to the stored offset for a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.Invalid">
            <summary>
                A special value that refers to an invalid, unassigned or default partition offset.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Offset.#ctor(System.Int64)">
            <summary>
                Initializes a new instance of the Offset structure.
            </summary>
            <param name="offset">
                The offset value
            </param>
        </member>
        <member name="P:Confluent.Kafka.Offset.Value">
            <summary>
                Gets the long value corresponding to this offset.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Offset.IsSpecial">
            <summary>
                Gets whether or not this is one of the special 
                offset values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Offset.Equals(System.Object)">
            <summary>
                Tests whether this Offset value is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is an Offset and has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.Equals(Confluent.Kafka.Offset)">
            <summary>
                Tests whether this Offset value is equal to the specified Offset.
            </summary>
            <param name="other">
                The offset to test.
            </param>
            <returns>
                true if other has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Equality(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Inequality(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is not equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_GreaterThan(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is greater than Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is greater than Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_LessThan(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is less than Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is less than Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_GreaterThanOrEqual(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is greater than or equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is greater than or equal to Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_LessThanOrEqual(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is less than or equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is less than or equal to Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Addition(Confluent.Kafka.Offset,System.Int32)">
            <summary>
                Add an integer value to an Offset value.
            </summary>
            <param name="a">
                The Offset value to add the integer value to.
            </param>
            <param name="b">
                The integer value to add to the Offset value.
            </param>
            <returns>
                The Offset value incremented by the integer value b.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Addition(Confluent.Kafka.Offset,System.Int64)">
            <summary>
                Add a long value to an Offset value.
            </summary>
            <param name="a">
                The Offset value to add the long value to.
            </param>
            <param name="b">
                The long value to add to the Offset value.
            </param>
            <returns>
                The Offset value incremented by the long value b.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.GetHashCode">
            <summary>
                Returns a hash code for this Offset.
            </summary>
            <returns>
                An integer that specifies a hash value for this Offset.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Implicit(System.Int64)~Confluent.Kafka.Offset">
            <summary>
                Converts the specified long value to an Offset value.
            </summary>
            <param name="v">
                The long value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Implicit(Confluent.Kafka.Offset)~System.Int64">
            <summary>
                Converts the specified Offset value to a long value.
            </summary>
            <param name="o">
                The Offset value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Offset.ToString">
            <summary>
                Returns a string representation of the Offset object.
            </summary>
            <returns>
                A string that represents the Offset object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Partition">
            <summary>
                Represents a Kafka partition.
            </summary>  
            <remarks>
                This structure is the same size as an int - 
                its purpose is to add some syntactical sugar 
                related to special values.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Partition.Any">
            <summary>
                A special value that refers to an unspecified / unknown partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Partition.#ctor(System.Int32)">
            <summary>
                Initializes a new instance of the Partition structure.
            </summary>
            <param name="partition">
                The partition value
            </param>
        </member>
        <member name="P:Confluent.Kafka.Partition.Value">
            <summary>
                Gets the long value corresponding to this partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Partition.IsSpecial">
            <summary>
                Gets whether or not this is one of the special 
                partition values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Partition.Equals(System.Object)">
            <summary>
                Tests whether this Partition value is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a Partition instance and has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.Equals(Confluent.Kafka.Partition)">
            <summary>
                Tests whether this Partition value is equal to the specified Partition.
            </summary>
            <param name="other">
                The partition to test.
            </param>
            <returns>
                true if other has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_Equality(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is equal to Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_Inequality(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is not equal to Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_GreaterThan(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is greater than Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a is greater than Partition value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_LessThan(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is less than Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a is less than Partition value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_GreaterThanOrEqual(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is greater than or equal to Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a is greater than or equal to Partition value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_LessThanOrEqual(Confluent.Kafka.Partition,Confluent.Kafka.Partition)">
            <summary>
                Tests whether Partition value a is less than or equal to Partition value b.
            </summary>
            <param name="a">
                The first Partition value to compare.
            </param>
            <param name="b">
                The second Partition value to compare.
            </param>
            <returns>
                true if Partition value a is less than or equal to Partition value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.GetHashCode">
            <summary>
                Returns a hash code for this Partition.
            </summary>
            <returns>
                An integer that specifies a hash value for this Partition.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_Implicit(System.Int32)~Confluent.Kafka.Partition">
            <summary>
                Converts the specified int value to an Partition value.
            </summary>
            <param name="v">
                The int value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Partition.op_Implicit(Confluent.Kafka.Partition)~System.Int32">
            <summary>
                Converts the specified Partition value to an int value.
            </summary>
            <param name="o">
                The Partition value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Partition.ToString">
            <summary>
                Returns a string representation of the Partition object.
            </summary>
            <returns>
                A string that represents the Partition object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.PartitionMetadata">
            <summary>
                Metadata pertaining to a single Kafka topic partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.PartitionMetadata.#ctor(System.Int32,System.Int32,System.Int32[],System.Int32[],Confluent.Kafka.Error)">
            <summary>
                Initializes a new PartitionMetadata instance.
            </summary>
            <param name="partitionId">
                The id of the partition this metadata relates to.
            </param>
            <param name="leader">
                The id of the broker that is the leader for the partition.
            </param>
            <param name="replicas">
                The ids of all brokers that contain replicas of the partition.
            </param>
            <param name="inSyncReplicas">
                The ids of all brokers that contain in-sync replicas of the partition.
                Note: this value is cached by the broker and is consequently not guarenteed to be up-to-date.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.PartitionMetadata.Error"/> object associated with the request for this partition metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.PartitionId">
            <summary>
                Gets ths id of the partition this metadata relates to.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Leader">
            <summary>
                Gets the id of the broker that is the leader for the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Replicas">
            <summary>
                Gets the ids of all brokers that contain replicas of the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.InSyncReplicas">
            <summary>
                Gets the ids of all brokers that contain in-sync replicas of the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.PartitionMetadata.Error"/> object associated with the request for this partition metadata.
                Note: this value is cached by the broker and is consequently not guarenteed to be up-to-date.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.PartitionMetadata.ToString">
            <summary>
                Returns a JSON representation of the PartitionMetadata object.
            </summary>
            <returns>
                A JSON representation the PartitionMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.ProduceException`2">
            <summary>
                Represents an error that occured whilst producing a message.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ProduceException`2.#ctor(Confluent.Kafka.Error,Confluent.Kafka.DeliveryReport{`0,`1})">
            <summary>
                Initialize a new instance of ProduceException based on 
                an existing Error value.
            </summary>
            <param name="error"> 
                The error associated with the delivery report.
            </param>
            <param name="deliveryReport">
                The delivery report associated with the produce request.
            </param>
        </member>
        <member name="P:Confluent.Kafka.ProduceException`2.DeliveryReport">
            <summary>
                The delivery report associated with the produce request.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Serializer`1">
            <summary>
                A serializer for use with <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
            <param name="topic">
                The topic the data is being produced to.
            </param>
            <param name="data">
                The value to serialize.
            </param>
            <returns>
                The serialized value.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.SerializerGenerator`1">
            <summary>
                A generator for <see cref="T:Confluent.Kafka.Serializer`1" /> instances.
            </summary>
            <param name="forKey">
                Whether or not the serializer is for use with keys.
            </param>
            <returns>
                The serializer.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Producer`2">
            <summary>
                Implements a high-level Apache Kafka producer with key
                and value serialization.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Confluent.Kafka.Serializer{`0},Confluent.Kafka.Serializer{`1})">
            <summary>
                Creates a new Producer instance.
            </summary>
            <param name="config">
                A collection of librdkafka configuration parameters 
                (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
                and parameters specific to this client (refer to: 
                <see cref="T:Confluent.Kafka.ConfigPropertyNames" />).
                At a minimum, 'bootstrap.servers' must be specified.
            </param>
            <param name="keySerializer">
                A delegate to use for serialize keys.
            </param>
            <param name="valueSerializer">
                A delegate to use for serialize values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Confluent.Kafka.SerializerGenerator{`0},Confluent.Kafka.SerializerGenerator{`1})">
            <summary>
                Creates a new Producer instance.
            </summary>
            <param name="config">
                A collection of librdkafka configuration parameters 
                (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
                and parameters specific to this client (refer to: 
                <see cref="T:Confluent.Kafka.ConfigPropertyNames" />).
                At a minimum, 'bootstrap.servers' must be specified.
            </param>
            <param name="keySerializerGenerator">
                A delegate to use to create a delegate for serializing keys.
            </param>
            <param name="valueSerializerGenerator">
                A delegate to use to create a delegate for serialize values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(Confluent.Kafka.Handle,Confluent.Kafka.Serializer{`0},Confluent.Kafka.Serializer{`1})">
            <summary>
                Creates a new Producer instance
            </summary>
            <param name="handle">
                A librdkafka handle to use for Kafka cluster communication.
            </param>
            <param name="keySerializer">
                A delegate to use for serialize keys.
            </param>
            <param name="valueSerializer">
                A delegate to use for serialize values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(Confluent.Kafka.Handle,Confluent.Kafka.SerializerGenerator{`0},Confluent.Kafka.SerializerGenerator{`1})">
            <summary>
                Creates a new Producer instance
            </summary>
            <param name="handle">
                A librdkafka handle to use for Kafka cluster communication.
            </param>
            <param name="keySerializerGenerator">
                A delegate to use to create a delegate for serializing keys.
            </param>
            <param name="valueSerializerGenerator">
                A delegate to use to create a delegate for serialize values.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Producer`2.Name">
            <summary>
                Refer to <see cref="P:Confluent.Kafka.IClient.Name" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Flush(System.TimeSpan)">
            <summary>
                Wait until all outstanding produce requests and delievery report
                callbacks are completed.
               
                [API-SUBJECT-TO-CHANGE] - the semantics and/or type of the return value
                is subject to change.
            </summary>
            <param name="timeout">
                The maximum length of time to block. You should typically use a
                relatively short timout period and loop until the return value
                becomes zero because this operation cannot be cancelled. 
            </param>
            <returns>
                The current librdkafka out queue length. This should be interpreted
                as a rough indication of the number of messages waiting to be sent
                to or acknowledged by the broker. If zero, there are no outstanding
                messages or callbacks. Specifically, the value is equal to the sum
                of the number of produced messages for which a delivery report has
                not yet been handled and a number which is less than or equal to the
                number of pending delivery report callback events (as determined by
                the number of outstanding protocol requests).
            </returns>
            <remarks>
                This method should typically be called prior to destroying a producer
                instance to make sure all queued and in-flight produce requests are
                completed before terminating. The wait time is bounded by the
                timeout parameter.
               
                A related configuration parameter is message.timeout.ms which determines
                the maximum length of time librdkafka attempts to deliver a message 
                before giving up and so also affects the maximum time a call to Flush 
                may block.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Flush(System.Threading.CancellationToken)">
            <summary>
                Wait until all outstanding produce requests and delievery report
                callbacks are completed.
            </summary>
            <remarks>
                This method should typically be called prior to destroying a producer
                instance to make sure all queued and in-flight produce requests are
                completed before terminating. 
               
                A related configuration parameter is message.timeout.ms which determines
                the maximum length of time librdkafka attempts to deliver a message 
                before giving up and so also affects the maximum time a call to Flush 
                may block.
            </remarks>
            <exception cref="T:System.OperationCanceledException">
                Thrown if the operation is cancelled.
            </exception>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Poll(System.TimeSpan)">
            <summary>
                Poll for callback events. Typically, you should not 
                call this method. Only call on producer instances 
                where background polling has been disabled.
            </summary>
            <param name="timeout">
                The maximum period of time to block if no callback events
                are waiting. You should typically use a relatively short 
                timout period because this operation cannot be cancelled.
            </param>
            <returns>
                Returns the number of events served.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Dispose">
            <summary>
                Releases all resources used by this Producer. In the current
                implementation, this method may block for up to 100ms. This 
                will be replaced with a non-blocking version in the future.
            </summary>
            <remarks>
                You will often want to call <see cref="M:Confluent.Kafka.Producer`2.Flush(System.Int32)" />
                before disposing a Producer instance to make sure all
                outstanding/queued messages are delivered.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Dispose(System.Boolean)">
            <summary>
                Releases the unmanaged resources used by the
                <see cref="T:Confluent.Kafka.Producer`2" />
                and optionally disposes the managed resources.
            </summary>
            <param name="disposing">
                true to release both managed and unmanaged resources;
                false to release only unmanaged resources.
            </param>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnLog">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnLog" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnStatistics">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnStatistics" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnError">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnError" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.AddBrokers(System.String)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.IClient.AddBrokers(System.String)" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer`2.Handle">
            <summary>
                An opaque reference to the underlying librdkafka client instance.
                This can be used to construct an <see cref="T:Confluent.Kafka.AdminClient" />
                or <see cref="T:Confluent.Kafka.Producer`2" /> instance that
                utilizes the same underlying librdkafka client as this Producer 
                instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Asynchronously send a single message to a Kafka topic.
                The partition the message is sent to is determined using
                the partitioner defined using the 'partitioner' 
                configuration property.
            </summary>
            <param name="topic">
                The topic to produce the message to.
            </param>
            <param name="message">
                The message to produce.
            </param>
            <param name="cancellationToken">
                A cancellation token that can be used to abort this request.
            </param>
            <returns>
                A Task which will complete with a delivery report corresponding to
                the produce request, or an exception if an error occured.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Threading.CancellationToken)">
            <summary>
                Asynchronously send a single message to a Kafka topic/partition.
            </summary>
            <param name="topicPartition">
                The topic/partition to produce the message to.
            </param>
            <param name="message">
                The message to produce.
            </param>
            <param name="cancellationToken">
                A cancellation token that can be used to abort this request.
            </param>
            <returns>
                A Task which will complete with a delivery report corresponding to
                the produce request, or an exception if an error occured.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.BeginProduce(Confluent.Kafka.TopicPartition,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})">
            <summary>
                Asynchronously send a single message to a Kafka topic/partition.
            </summary>
            <param name="topicPartition">
                The topic/partition to produce the message to.
            </param>
            <param name="message">
                The message to produce.
            </param>
            <param name="deliveryHandler">
                A delegate that will be called with a delivery report corresponding
                to the produce request (if enabled).
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.BeginProduce(System.String,Confluent.Kafka.Message{`0,`1},System.Action{Confluent.Kafka.DeliveryReportResult{`0,`1}})">
            <summary>
                Asynchronously send a single message to a Kafka topic.
                The partition the message is sent to is determined using
                the partitioner defined using the 'partitioner' 
                configuration property.
            </summary>
            <param name="topic">
                The topic to produce the message to.
            </param>
            <param name="message">
                The message to produce.
            </param>
            <param name="deliveryHandler">
                A delegate that will be called with a delivery report corresponding
                to the produce request (if enabled).
            </param>
        </member>
        <member name="T:Confluent.Kafka.Producer">
            <summary>
                A high-level Apache Kafka producer (without serialization).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.Topic">
            <summary>
                The topic associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.Partition">
            <summary>
                The partition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.Offset">
            <summary>
                The partition offset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.Error">
            <summary>
                An error (or NoError) associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.TopicPartition">
            <summary>
                The TopicPartition associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.TopicPartitionOffset">
            <summary>
                The TopicPartitionOffset associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.TopicPartitionOffsetError">
            <summary>
                The TopicPartitionOffsetError assoicated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.UntypedDeliveryReport.Message">
            <summary>
                The message that was produced.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.DeliveryReportCallbackImpl(System.IntPtr,System.IntPtr,System.IntPtr)">
            <remarks>
                note: this property is set to that defined in rd_kafka_conf
                (which is never used by confluent-kafka-dotnet).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnLog">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnLog" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnError">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnError" />.
            </summary>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnStatistics">
            <summary>
                Refer to <see cref="E:Confluent.Kafka.IClient.OnStatistics" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}})">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.Poll(System.TimeSpan)">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.Flush(System.TimeSpan)">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.Dispose">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.Dispose(System.Boolean)">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.Name">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.AddBrokers(System.String)">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.Handle">
            <summary>
                <see cref="T:Confluent.Kafka.Producer`2" />
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Serializers">
            <summary>
                Serializers that can be used with <see cref="T:Confluent.Kafka.Producer`2" />.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.UTF8">
            <summary>
                Encodes a string value in a byte array.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Null">
            <summary>
                Encodes a Null value to null.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serializers.Long(System.String,System.Int64)">
            <summary>
                Serializes the specified <see cref="T:System.Int64"/> value to a byte array of length 8. Byte order is big endian (network byte order).
            </summary>
            <param name="data">
                The <see cref="T:System.Int64"/> value to serialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                The <see cref="T:System.Int64"/> value <paramref name="data" /> encoded as a byte array of length 8 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serializers.Int32(System.String,System.Int32)">
            <summary>
                Serializes the specified <see cref="T:System.Int32"/> value to a byte array of length 4. Byte order is big endian (network byte order).
            </summary>
            <param name="data">
                The <see cref="T:System.Int32"/> value to serialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                The <see cref="T:System.Int32"/> value <paramref name="data" /> encoded as a byte array of length 4 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serializers.Float(System.String,System.Single)">
            <summary>
                Serializes the specified System.Single value to a byte array of length 4. Byte order is big endian (network byte order).
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <param name="data">
                The System.Single value to serialize.
            </param>
            <returns>
                The System.Single value <paramref name="data" /> encoded as a byte array of length 4 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serializers.Double(System.String,System.Double)">
            <summary>
                Serializes the specified System.Double value to a byte array of length 8. Byte order is big endian (network byte order).
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <param name="data">
                The System.Double value to serialize.
            </param>
            <returns>
                The System.Double value <paramref name="data" /> encoded as a byte array of length 4 (network byte order).
            </returns>
        </member>
        <member name="F:Confluent.Kafka.Serializers.ByteArray">
            <summary>
                Serializes the specified System.Byte[] value (or null) to 
                a byte array. Byte order is original order. 
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Serializers.Generators">
            <summary>
                Generators for the standard serializers (simply return the 
                appropriate serializer regardless of the value of the forKey
                parameter)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.UTF8">
            <summary>
                Generates a UTF8 serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.Null">
            <summary>
                Generates a Null serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.Int32">
            <summary>
                Generates a Int32 serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.Long">
            <summary>
                Generates a Long serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.Float">
            <summary>
                Generates a Float serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serializers.Generators.Double">
            <summary>
                Generates a Double serializer (invariant on the value of forKey).
            </summary>
        </member>
        <member name="T:Confluent.Kafka.SyslogLevel">
            <summary>
                Represents enumeration with levels comming from syslog(3)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Emergency">
            <summary>
                System is unusable.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Alert">
            <summary>
                Action must be take immediately
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Critical">
            <summary>
                Critical condition.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Error">
            <summary>
                Error condition.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Warning">
            <summary>
                Warning condition.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Notice">
            <summary>
                Normal, but significant condition.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Info">
            <summary>
                Informational message.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.SyslogLevel.Debug">
            <summary>
                Debug-level message.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Timestamp">
            <summary>
                Encapsulates a Kafka timestamp and its type.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.Default">
            <summary>
                A read-only field representing an unspecified timestamp.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Timestamp.UnixTimeEpoch">
            <summary>
                Unix epoch as a UTC DateTime. Unix time is defined as 
                the number of seconds past this UTC time, excluding 
                leap seconds.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.Int64,Confluent.Kafka.TimestampType)">
            <summary>
                Initializes a new instance of the Timestamp structure.
            </summary>
            <param name="unixTimestampMs">
                The unix millisecond timestamp.
            </param>
            <param name="type">
                The type of the timestamp.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.DateTime,Confluent.Kafka.TimestampType)">
            <summary>
                Initializes a new instance of the Timestamp structure.
                Note: <paramref name="dateTime"/> is first converted to UTC 
                if it is not already.
            </summary>
            <param name="dateTime">
                The DateTime value corresponding to the timestamp.
            </param>
            <param name="type">
                The type of the timestamp.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.DateTime)">
            <summary>
                Initializes a new instance of the Timestamp structure.
                Note: <paramref name="dateTime" /> is first converted
                to UTC if it is not already and TimestampType is set
                to CreateTime.
            </summary>
            <param name="dateTime">
                The DateTime value corresponding to the timestamp.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.DateTimeOffset)">
            <summary>
                Initializes a new instance of the Timestamp structure.
                Note: TimestampType is set to CreateTime.
            </summary>
            <param name="dateTimeOffset">
                The DateTimeOffset value corresponding to the timestamp.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.Type">
            <summary>
                Gets the timestamp type.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.UnixTimestampMs">
            <summary>
                Get the Unix millisecond timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.UtcDateTime">
            <summary>
                Gets the UTC DateTime corresponding to the <see cref="P:Confluent.Kafka.Timestamp.UnixTimestampMs"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.Equals(System.Object)">
            <summary>
                Determines whether two Timestamps have the same value.
            </summary>
            <param name="obj">
                Determines whether this instance and a specified object, 
                which must also be a Timestamp object, have the same value.
            </param>
            <returns>
                true if obj is a Timestamp and its value is the same as 
                this instance; otherwise, false. If obj is null, the method 
                returns false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.Equals(Confluent.Kafka.Timestamp)">
            <summary>
                Determines whether two Timestamps have the same value.
            </summary>
            <param name="other">
                The timestamp to test.
            </param>
            <returns>
                true if other has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.GetHashCode">
            <summary>
                Returns the hashcode for this Timestamp.
            </summary>
            <returns>
                A 32-bit signed integer hash code.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.op_Equality(Confluent.Kafka.Timestamp,Confluent.Kafka.Timestamp)">
            <summary>
                Determines whether two specified Timestamps have the same value.
            </summary>
            <param name="a">
                The first Timestamp to compare.
            </param>
            <param name="b">
                The second Timestamp to compare
            </param>
            <returns>
                true if the value of a is the same as the value of b; otherwise, false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.op_Inequality(Confluent.Kafka.Timestamp,Confluent.Kafka.Timestamp)">
            <summary>
                Determines whether two specified Timestamps have different values.
            </summary>
            <param name="a">
                The first Timestamp to compare.
            </param>
            <param name="b">
                The second Timestamp to compare
            </param>
            <returns>
                true if the value of a is different from the value of b; otherwise, false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.DateTimeToUnixTimestampMs(System.DateTime)">
            <summary>
                Convert a DateTime instance to a milliseconds unix timestamp.
                Note: <paramref name="dateTime"/> is first converted to UTC 
                if it is not already.
            </summary>
            <param name="dateTime">
                The DateTime value to convert.
            </param>
            <returns>
                The milliseconds unix timestamp corresponding to <paramref name="dateTime"/>
                rounded down to the previous millisecond.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.UnixTimestampMsToDateTime(System.Int64)">
            <summary>
                Convert a milliseconds unix timestamp to a DateTime value.
            </summary>
            <param name="unixMillisecondsTimestamp">
                The milliseconds unix timestamp to convert.
            </param>
            <returns>
                The DateTime value associated with <paramref name="unixMillisecondsTimestamp"/> with Utc Kind.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TimestampType">
            <summary>
                Enumerates the different meanings of a message timestamp value.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.NotAvailable">
            <summary>
                Timestamp type is unknown.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.CreateTime">
            <summary>
                Timestamp relates to message creation time as set by a Kafka client.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.LogAppendTime">
            <summary>
                Timestamp relates to the time a message was appended to a Kafka log.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TopicMetadata">
            <summary>
                Metadata pertaining to a single Kafka topic.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicMetadata.#ctor(System.String,System.Collections.Generic.List{Confluent.Kafka.PartitionMetadata},Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicMetadata class instance.
            </summary>
            <param name="topic">
                The topic name.
            </param>
            <param name="partitions">
                Metadata for each of the topic's partitions.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.TopicMetadata.Error"/> object associated with the request for this topic metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Topic">
            <summary>
                Gets the topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Partitions">
            <summary>
                Gets metadata for each of the topics partitions.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Error">
            <summary>
                A rich <see cref="P:Confluent.Kafka.TopicMetadata.Error"/> object associated with the request for this topic metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicMetadata.ToString">
            <summary>
                Returns a JSON representation of the TopicMetadata object.
            </summary>
            <returns>
                A JSON representation the TopicMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartition">
            <summary>
                Represents a Kafka (topic, partition) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.#ctor(System.String,Confluent.Kafka.Partition)">
            <summary>
                Initializes a new TopicPartition instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartition.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartition.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartition instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartition and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartition.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartition.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.op_Equality(Confluent.Kafka.TopicPartition,Confluent.Kafka.TopicPartition)">
            <summary>
                Tests whether TopicPartition instance a is equal to TopicPartition instance b.
            </summary>
            <param name="a">
                The first TopicPartition instance to compare.
            </param>
            <param name="b">
                The second TopicPartition instance to compare.
            </param>
            <returns>
                true if TopicPartition instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.op_Inequality(Confluent.Kafka.TopicPartition,Confluent.Kafka.TopicPartition)">
            <summary>
                Tests whether TopicPartition instance a is not equal to TopicPartition instance b.
            </summary>
            <param name="a">
                The first TopicPartition instance to compare.
            </param>
            <param name="b">
                The second TopicPartition instance to compare.
            </param>
            <returns>
                true if TopicPartition instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.ToString">
            <summary>
                Returns a string representation of the TopicPartition object.
            </summary>
            <returns>
                A string that represents the TopicPartition object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionError">
            <summary>
                Represents a Kafka (topic, partition, error) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionError instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition values.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.#ctor(System.String,Confluent.Kafka.Partition,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionError instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Error">
            <summary>
                Gets the Kafka error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionError instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionError instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionError and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionError.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionError.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.op_Equality(Confluent.Kafka.TopicPartitionError,Confluent.Kafka.TopicPartitionError)">
            <summary>
                Tests whether TopicPartitionError instance a is equal to TopicPartitionError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionError instance to compare.
            </param>
            <returns>
                true if TopicPartitionError instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.op_Inequality(Confluent.Kafka.TopicPartitionError,Confluent.Kafka.TopicPartitionError)">
            <summary>
                Tests whether TopicPartitionError instance a is not equal to TopicPartitionError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionError instance to compare.
            </param>
            <returns>
                true if TopicPartitionError instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.ToString">
            <summary>
                Returns a string representation of the TopicPartitionError object.
            </summary>
            <returns>
                A string representation of the TopicPartitionError object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionOffset">
            <summary>
                Represents a Kafka (topic, partition, offset) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new TopicPartitionOffset instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.#ctor(System.String,Confluent.Kafka.Partition,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new TopicPartitionOffset instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Offset">
            <summary>
                Gets the Kafka partition offset value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionOffset instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionOffset instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionOffset and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionOffset.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionOffset.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.op_Equality(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Tests whether TopicPartitionOffset instance a is equal to TopicPartitionOffset instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffset instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffset instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffset instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.op_Inequality(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Tests whether TopicPartitionOffset instance a is not equal to TopicPartitionOffset instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffset instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffset instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffset instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.ToString">
            <summary>
                Returns a string representation of the TopicPartitionOffset object.
            </summary>
            <returns>
                A string that represents the TopicPartitionOffset object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionOffsetError">
            <summary>
                Represents a Kafka (topic, partition, offset, error) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Offset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition values.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="tpo">
                Kafka topic name, partition and offset values.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(System.String,Confluent.Kafka.Partition,Confluent.Kafka.Offset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition value.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Offset">
            <summary>
                Gets the Kafka partition offset value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Error">
            <summary>
                Gets the Kafka error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionOffsetError instance.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.TopicPartitionOffset">
            <summary>
                Gets the TopicPartitionOffset component of this TopicPartitionOffsetError instance.
            </summary>>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionOffsetError instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionOffsetError and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionOffsetError.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionOffsetError.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Equality(Confluent.Kafka.TopicPartitionOffsetError,Confluent.Kafka.TopicPartitionOffsetError)">
            <summary>
                Tests whether TopicPartitionOffsetError instance a is equal to TopicPartitionOffsetError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffsetError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffsetError instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffsetError instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Inequality(Confluent.Kafka.TopicPartitionOffsetError,Confluent.Kafka.TopicPartitionOffsetError)">
            <summary>
                Tests whether TopicPartitionOffsetError instance a is not equal to TopicPartitionOffsetError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffsetError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffsetError instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffsetError instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Explicit(Confluent.Kafka.TopicPartitionOffsetError)~Confluent.Kafka.TopicPartitionOffset">
            <summary>
                Converts TopicPartitionOffsetError instance to TopicPartitionOffset instance.
                NOTE: Throws KafkaException if Error.Code != ErrorCode.NoError 
            </summary>
            <param name="tpoe">
                The TopicPartitionOffsetError instance to convert.
            </param>
            <returns>
                TopicPartitionOffset instance converted from TopicPartitionOffsetError instance
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.ToString">
            <summary>
                Returns a string representation of the TopicPartitionOffsetError object.
            </summary>
            <returns>
                A string representation of the TopicPartitionOffsetError object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionTimestamp">
            <summary>
                Represents a Kafka (topic, partition, timestamp) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Timestamp)">
            <summary>
                Initializes a new TopicPartitionTimestamp instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition.
            </param>
            <param name="timestamp">
                A Kafka timestamp value.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.#ctor(System.String,Confluent.Kafka.Partition,Confluent.Kafka.Timestamp)">
            <summary>
                Initializes a new TopicPartitionTimestamp instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
            <param name="timestamp">
                A Kafka timestamp value.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Timestamp">
            <summary>
                Gets the Kafka timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionTimestamp instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionTimestamp instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionTimestamp and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionTimestamp.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionTimestamp.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.op_Equality(Confluent.Kafka.TopicPartitionTimestamp,Confluent.Kafka.TopicPartitionTimestamp)">
            <summary>
                Tests whether TopicPartitionTimestamp instance a is equal to TopicPartitionTimestamp instance b.
            </summary>
            <param name="a">
                The first TopicPartitionTimestamp instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionTimestamp instance to compare.
            </param>
            <returns>
                true if TopicPartitionTimestamp instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.op_Inequality(Confluent.Kafka.TopicPartitionTimestamp,Confluent.Kafka.TopicPartitionTimestamp)">
            <summary>
                Tests whether TopicPartitionTimestamp instance a is not equal to TopicPartitionTimestamp instance b.
            </summary>
            <param name="a">
                The first TopicPartitionTimestamp instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionTimestamp instance to compare.
            </param>
            <returns>
                true if TopicPartitionTimestamp instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.ToString">
            <summary>
                Returns a string representation of the TopicPartitionTimestamp object.
            </summary>
            <returns>
                A string that represents the TopicPartitionTimestamp object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.WatermarkOffsets">
            <summary>
                Represents the low and high watermark offsets of a Kafka 
                topic/partition.
            </summary>
            <remarks>
                You can identify a partition that has not yet been written
                to by checking if the high watermark equals 0.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.WatermarkOffsets.#ctor(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new instance of the WatermarkOffsets class
                with the specified offsets.
            </summary>
            <param name="low">
                The offset of the earlist message in the topic/partition. If 
                no messages have been written to the topic, the low watermark
                offset is set to 0. The low watermark will also be 0 if 
                one message has been written to the partition (with offset 0).
            </param>
            <param name="high">
                The high watermark offset, which is the offset of the latest
                message in the topic/partition available for consumption + 1.
            </param>
        </member>
        <member name="P:Confluent.Kafka.WatermarkOffsets.Low">
            <summary>
                Gets the offset of the earlist message in the topic/partition. If 
                no messages have been written to the topic, the low watermark
                offset is set to 0. The low watermark will also be 0 if 
                one message has been written to the partition (with offset 0).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.WatermarkOffsets.High">
            <summary>
                Gets the high watermark offset, which is the offset of the latest
                message in the topic/partition available for consumption + 1.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.WatermarkOffsets.ToString">
            <summary>
                Returns a string representation of the WatermarkOffsets object.
            </summary>
            <returns>
                A string representation of the WatermarkOffsets object.
            </returns>
        </member>
    </members>
</doc>
